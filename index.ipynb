{
 "cells": [
  {
   "cell_type": "raw",
   "id": "170215c2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"{{< var pub.title >}} --\"\n",
    "date: 'January 1, 2025'\n",
    "abstract-title: \"Summary\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2ab58-9efe-4758-a50d-8f9e011fe2cd",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Despite the header being `## Abstract`, this section will render as a highlighted section titled *Summary*. Ensure this section is a **maximum** of 280 characters.\n",
    "\n",
    "----\n",
    "\n",
    ":::{.callout-note title=\"AI usage disclosure\" collapse=\"true\"}\n",
    "This is a placeholder for the AI usage disclosure. Once all authors sign the AI code form on Airtable, SlackBot will message you an AI disclosure that you should place here.\n",
    ":::\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Once edited by you, this file will become your publication. Alternatively, if you already have a notebook written that you're trying to transform into a pub, replace this file with your own, but be sure to add the YAML front matter (the first cell) to your notebook.\n",
    "\n",
    "Your pub should begin with a section titled **Purpose** where you, as briefly as possible, explain why you did the work described in the pub, the key takeaway, your primary audience, and how you think it could be useful to them/why you're sharing it.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "MSA Pairformer achieves state-of-the-art performance in protein structure and function prediction, largely due to its innovative query-biased attention mechanism [@Akiyama2025]. The authors put forward a compelling hypothesis for this success: by learning to weight sequences based on their evolutionary relevance, the model mitigates phylogenetic averaging and amplifies faint, subfamily-specific signals.\n",
    "\n",
    "The original paper supported this by showing the model's attention weights could separate subfamilies. While compelling, this was not a fully-fledged characterization of how sequence weights map onto phylogenetic structure, and was demonstrated for just one protein family---a response regulator family. This leaves open the question of how precisely, and how generally, the model's attention mechanism recapitulates evolutionary relatedness.\n",
    "\n",
    "In this work, we explore these questions directly. We begin by revisiting the response regulator family to ground our analysis, and then expand our investigation to thousands of MSAs across the tree of life. Our goal is to scope out the anatomy of the model's evolutionary understanding on a broad scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e6bb5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Revisiting the response regulator study\n",
    "\n",
    "The response regulator (RR) family was the original paper's showcase for demonstrating the power of query-biased attention. By constructing a mixed MSA of [GerE](https://www.ebi.ac.uk/interpro/entry/pfam/PF00196/), [LytTR](https://www.ebi.ac.uk/interpro/entry/pfam/PF04397/), and [OmpR](https://www.ebi.ac.uk/interpro/entry/pfam/PF00486/) subfamilies, the authors showed MSA Pairformer could successfully identify key structural contacts unique to each subfamily.\n",
    "\n",
    "They illustrated the mechanism behind this success by plotting model sequence weights against Hamming distance[^hamming], revealing that members of the query's subfamily were consistently upweighted, as shown below.\n",
    "\n",
    "![Figure 4B from @Akiyama2025. Original caption: \"*Median sequence weight across the layers of the model versus Hamming distance to the query sequence. Top panels show distribution of sequence attention weights for subfamily members (red) and non-subfamily sequences (grey). Grey dotted line indicates weights used for uniform sequence attention and red dotted line indicates weight assigned to the query sequence.*\"](assets/figure4b.jpg){fig-align=\"center\" width=100% fig-alt=\"Figure 4B from @Akiyama2025 showing the relationship between median sequence weight and Hamming distance to the query.\"}\n",
    "\n",
    "We can build on this analysis by replacing the proxy of Hamming distance with a formal phylogenetic tree, which would allow us to ask a more nuanced question: Do the model's sequence weights reflect the continuous distances of evolutionary history, or do they simply create a binary distinction between \"in-group\" and \"out-group\"?\n",
    "\n",
    "To ground our phylogenetic analysis in the paper's original findings, we start by replicating the dataset. Following the protocol laid out by @Akiyama2025, we begin by downloading the full PFAM alignments for the GerE, LytTR, and OmpR subfamilies, combining them, and then sampling a final set of 4096 sequences to match the dataset used in the study.\n",
    "\n",
    "[^hamming]: Hamming distance is the number of positions at which two sequences of equal length differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4a911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:31.815112Z",
     "iopub.status.busy": "2025-10-06T19:53:31.814650Z",
     "iopub.status.idle": "2025-10-06T19:53:31.848506Z",
     "shell.execute_reply": "2025-10-06T19:53:31.847952Z"
    }
   },
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "%env TQDM_DISABLE_NOTEBOOK=0\n",
    "%env USE_MODAL=1\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e4a07",
   "metadata": {},
   "source": [
    ":::{.callout-note title=\"Reproducing the response regulator MSAs\"}\n",
    "\n",
    "@Akiyama2025 qualitatively describe how to reproduce the response regulator MSAs, however these details are insufficient for exact replication. The code below is our attempted reproduction, and we find these MSAs yield similar, yet not identical, sequence weight statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9109183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:31.850808Z",
     "iopub.status.busy": "2025-10-06T19:53:31.850627Z",
     "iopub.status.idle": "2025-10-06T19:53:34.160754Z",
     "shell.execute_reply": "2025-10-06T19:53:34.160353Z"
    }
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Response regulator MSA code\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from analysis.pfam import download_and_process_response_regulator_msa\n",
    "\n",
    "from MSA_Pairformer.dataset import MSA\n",
    "\n",
    "response_regulator_dir = Path(\"./data/response_regulators\")\n",
    "response_regulator_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rr_msas: dict[str, MSA] = {}\n",
    "\n",
    "rr_queries = {\"1NXS\": \"OmpR\", \"4CBV\": \"LytTR\", \"4E7P\": \"GerE\"}\n",
    "for query in rr_queries:\n",
    "    msa_path = response_regulator_dir / f\"PF00072.final_{query}.a3m\"\n",
    "\n",
    "    if not msa_path.exists():\n",
    "        download_and_process_response_regulator_msa(\n",
    "            output_dir=response_regulator_dir,\n",
    "            subset_size=4096,\n",
    "        )\n",
    "\n",
    "    rr_msas[query] = MSA(msa_file_path=msa_path, diverse_select_method=\"none\")\n",
    "\n",
    "example_msa = rr_msas[query]\n",
    "membership_path = response_regulator_dir / \"membership.txt\"\n",
    "target_to_subfamily = (\n",
    "    pd.read_csv(membership_path, sep=\"\\t\").set_index(\"record_id\")[\"subfamily\"].to_dict()\n",
    ")\n",
    "\n",
    "print(f\"MSA has {len(example_msa.ids_l)} sequences:\")\n",
    "\n",
    "subfamily_member_count = Counter()\n",
    "for sequence in example_msa.ids_l:\n",
    "    subfamily_member_count[target_to_subfamily[sequence]] += 1\n",
    "\n",
    "for subfamily, count in subfamily_member_count.items():\n",
    "    print(f\"  - {subfamily} sequences: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e7123",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "To infer a tree for this MSA, we use [FastTree](https://morgannprice.github.io/fasttree/), a rapid method for approximating maximum-likelihood phylogenies suitable for trees of this size [@Price2009]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099474ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Tree inference code\n",
    "\n",
    "from analysis.tree import read_newick, run_fasttree\n",
    "\n",
    "fasttree_path = response_regulator_dir / \"PF00072.final.fasttree.newick\"\n",
    "msa_for_tree = response_regulator_dir / \"PF00072.final.fasta\"\n",
    "if not fasttree_path.exists():\n",
    "    run_fasttree(msa_path.with_suffix(\".fasta\"), fasttree_path)\n",
    "\n",
    "rr_tree = read_newick(fasttree_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f46270",
   "metadata": {},
   "source": [
    "Visualizing this tree provides our first direct look at the evolutionary structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Tree visualization code\n",
    "# | label: fig-rr-tree\n",
    "# | fig-cap: A randomly selected subset of the response regulator family illustrating the tree structure. The RSCB structure ID is labelled for the query sequence of each subfamily. Leaves are colored according to subfamily  ([⬤]{style=\"color:#5088C5\"} [GerE](https://www.ebi.ac.uk/interpro/entry/pfam/PF00196/), [⬤]{style=\"color:#F28360\"} [OmpR](https://www.ebi.ac.uk/interpro/entry/pfam/PF00486/), [⬤]{style=\"color:#3B9886\"} [LytTR](https://www.ebi.ac.uk/interpro/entry/pfam/PF04397/)).\n",
    "\n",
    "import arcadia_pycolor as apc\n",
    "from analysis.plotting import tree_style_with_categorical_annotation\n",
    "from analysis.tree import read_newick, subset_tree\n",
    "\n",
    "query_colors = {\n",
    "    \"4E7P\": apc.aegean,\n",
    "    \"1NXS\": apc.amber,\n",
    "    \"4CBV\": apc.seaweed,\n",
    "}\n",
    "subfamily_colors = {rr_queries[k]: v for k, v in query_colors.items()}\n",
    "\n",
    "tree_style = tree_style_with_categorical_annotation(\n",
    "    categories=target_to_subfamily,\n",
    "    highlight=list(rr_queries),\n",
    "    color_map=subfamily_colors,\n",
    ")\n",
    "visualized_tree = subset_tree(tree=rr_tree, n=100, force_include=list(rr_queries), seed=42)\n",
    "visualized_tree.render(\"%%inline\", tree_style=tree_style, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13247c9",
   "metadata": {},
   "source": [
    "We expect to see distinct, well-supported clades corresponding to the three subfamilies, which is more or less what we observe in @fig-rr-tree. Discrepancies from this expectation highlight the importance of clade grouping based on explicit tree calculation, rather than relying on PFAM domains. \n",
    "\n",
    "To compare against our phylogenetic \"ground truth,\" we need to generate the model's query-biased sequence weights, which are hypothesized to capture evolutionary relatedness. To do this, we'll run an MSA Pairformer inference three separate times. Each run will use a different subfamily representative as the query, yielding three distinct, query-biased sets of sequence weights.\n",
    "\n",
    ":::{.callout-note title=\"Running MSA Pairformer...\"}\n",
    "In order to reproduce this step of the workflow, you'll need a GPU with at least 40Gb of GPU VRAM. We don't assume you have that hardware handy, so we've stored pre-computed inference results (`data/response_regulators/inference_results.pt`), and by default, the code below will load these inference results rather than re-computing. If you have the necessary hardware and want to re-compute the inference, delete this file prior to running the cell below, and the file will be regenerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c577a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:35.897200Z",
     "iopub.status.busy": "2025-10-06T19:53:35.897097Z",
     "iopub.status.idle": "2025-10-06T19:53:36.398419Z",
     "shell.execute_reply": "2025-10-06T19:53:36.398052Z"
    }
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: MSA inference code\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from analysis.pairformer import run_inference\n",
    "\n",
    "inference_results_path = response_regulator_dir / \"inference_results.pt\"\n",
    "if inference_results_path.exists():\n",
    "    rr_inference_results = torch.load(inference_results_path, weights_only=True)\n",
    "else:\n",
    "    rr_inference_results: dict[str, dict[str, Any]] = {}\n",
    "    for query in rr_queries:\n",
    "        rr_inference_results[query] = run_inference(\n",
    "            rr_msas[query], return_seq_weights=True, query_only=True\n",
    "        )\n",
    "\n",
    "    torch.save(rr_inference_results, inference_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4239703",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "We now have our two key components: a **phylogenetic tree** for the RR family (our evolutionary \"ground truth\") and the model's **sequence weights** relative to each of the three subfamily queries. Before diving into a formal statistical analysis, let's build an intuition for how the model's attention relates to tree structure by visualizing weights directly onto the tree.\n",
    "\n",
    "For each of the three queries, let's center our view on a small subset of the full MSA (for ease of visualization) and color at each leaf the median (across layers) sequence weight it received from the model. If the model is capturing evolutionary relatedness, we'd expect a gradient of sequence weight that follows the tree's branches away from the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c85d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | label: fig-tree-weight-paint\n",
    "# | fig-cap: Trees for each query, where each leaf is colored according to the median sequence weight it received from the model. Darker nodes signify sequences receiving high levels of attention (upweighting), while lighter nodes signify sequences receiving low levels of attention (downweighting). Each tree is subset to 100 sequences sampled from the full tree (includes all subfamilies). To better visualize a gradient, sequences were sampled with a probability inversely proportional to their phylogenetic rank distance from the query, raised to a power of 0.8, which combine to give slight preference for selecting sequences phylogenetically similar to the query.\n",
    "# | fig-subcap:\n",
    "# |   - \"Median sequence weights with respect to 1NXS (OmpR).\"\n",
    "# |   - \"Median sequence weights with respect to 4CBV (LytTR).\"\n",
    "# |   - \"Median sequence weights with respect to 4E7P (GerE).\"\n",
    "# | layout-ncol: 1\n",
    "\n",
    "from analysis.data import get_sequence_weight_data\n",
    "from analysis.plotting import tree_style_with_scalar_annotation\n",
    "from analysis.tree import (\n",
    "    sort_tree_by_reference,\n",
    "    subset_tree_around_reference,\n",
    ")\n",
    "from IPython.display import display\n",
    "\n",
    "rr_data_dict = dict(\n",
    "    query=[],\n",
    "    target=[],\n",
    "    median_weight=[],\n",
    ")\n",
    "\n",
    "for query in rr_queries:\n",
    "    msa = rr_msas[query]\n",
    "    targets = msa.ids_l\n",
    "\n",
    "    weights = get_sequence_weight_data(rr_inference_results[query])\n",
    "\n",
    "    # For each layer, sequence weights sum to 1. Scaling by number of\n",
    "    # sequences yields a scale where 1 implies uniform weighting.\n",
    "    weights *= weights.size(0)\n",
    "\n",
    "    median_weights = torch.median(weights, dim=1).values\n",
    "\n",
    "    rr_data_dict[\"query\"].extend([query] * len(targets))\n",
    "    rr_data_dict[\"target\"].extend(targets)\n",
    "    rr_data_dict[\"median_weight\"].extend(median_weights.tolist())\n",
    "\n",
    "response_regulator_df = pd.DataFrame(rr_data_dict)\n",
    "\n",
    "tree_images = []\n",
    "queries_list = response_regulator_df[\"query\"].unique()\n",
    "for query in queries_list:\n",
    "    color = query_colors[query]\n",
    "    specific_layer = \"median_weight\"\n",
    "    specific_layer_weights = (\n",
    "        response_regulator_df.loc[\n",
    "            (response_regulator_df[\"query\"] == query) & (response_regulator_df[\"query\"] != response_regulator_df[\"target\"]), [specific_layer, \"target\"]\n",
    "        ]\n",
    "        .set_index(\"target\")[specific_layer]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    gradient = apc.Gradient.from_dict(\n",
    "        \"gradient\",\n",
    "        {\"1\": \"#EEEEEE\", \"2\": \"#EEEEEE\", \"3\": color, \"4\": color},\n",
    "        values=[0.0, 0.0, 0.75, 1.0],\n",
    "    )\n",
    "    tree_style = tree_style_with_scalar_annotation(\n",
    "        specific_layer_weights, gradient, highlight=[query]\n",
    "    )\n",
    "    visualized_tree = sort_tree_by_reference(\n",
    "        subset_tree_around_reference(tree=rr_tree, n=100, reference=query, bias_power=0.8, seed=42),\n",
    "        query,\n",
    "    )\n",
    "    tree_images.append(visualized_tree.render(\"%%inline\", tree_style=tree_style, dpi=300))\n",
    "\n",
    "display(*tree_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06c75d",
   "metadata": {},
   "source": [
    "Encouragingly, @fig-tree-weight-paint provides an intuitive picture: weights with respect to *1NXS* and *4CBV* visually correlate with distance from the query, suggesting the model's attention mechanism prioritizes evolutionary relatedness. However, the picture is less clear for *4E7P*, which invites a quantitative test.\n",
    "\n",
    "To formalize this observation, let's extract the *patristic tree distance*[^1] between the queries and all the other sequences in the MSA, then compare this to the model's median sequence weights. As in @Akiyama2025, we'll normalize weights by the number of sequences, so a value of 1 represents the uniform weighting baseline and a value greater than 1 indicates upweighting. And on the suspicion that this median value might smooth over layer-specific complexity, let's also store the individual weights from each layer to leave room for a more granular, layer-by-layer analysis.\n",
    "\n",
    "[^1]: Patristic tree distance is the distance between two members of a phylogenetic tree, calculated as the sum of branch lengths connecting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38773b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:36.400073Z",
     "iopub.status.busy": "2025-10-06T19:53:36.399872Z",
     "iopub.status.idle": "2025-10-06T19:53:36.779992Z",
     "shell.execute_reply": "2025-10-06T19:53:36.779469Z"
    }
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "\n",
    "from analysis.data import get_sequence_weight_data\n",
    "from analysis.tree import get_patristic_distance\n",
    "from scipy.stats import linregress\n",
    "\n",
    "rr_data_dict = dict(\n",
    "    query=[],\n",
    "    target_subfamily=[],\n",
    "    target=[],\n",
    "    patristic_distance=[],\n",
    "    median_weight=[],\n",
    ")\n",
    "\n",
    "num_layers = 22\n",
    "for layer_idx in range(num_layers):\n",
    "    rr_data_dict[f\"layer_{layer_idx}_weight\"] = []\n",
    "\n",
    "for query in rr_queries:\n",
    "    msa = rr_msas[query]\n",
    "    targets = msa.ids_l\n",
    "\n",
    "    patristic_distances = get_patristic_distance(rr_tree, query)\n",
    "    patristic_distances = patristic_distances[targets]\n",
    "\n",
    "    weights = get_sequence_weight_data(rr_inference_results[query])\n",
    "\n",
    "    # For each layer, sequence weights sum to 1. Scaling by number of\n",
    "    # sequences yields a scale where 1 implies uniform weighting.\n",
    "    weights *= weights.size(0)\n",
    "\n",
    "    median_weights = torch.median(weights, dim=1).values\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        rr_data_dict[f\"layer_{layer_idx}_weight\"].extend(weights[:, layer_idx].tolist())\n",
    "\n",
    "    rr_data_dict[\"query\"].extend([query] * len(targets))\n",
    "    rr_data_dict[\"target_subfamily\"].extend(\n",
    "        [target_to_subfamily[target] for target in targets]\n",
    "    )\n",
    "    rr_data_dict[\"target\"].extend(targets)\n",
    "    rr_data_dict[\"median_weight\"].extend(median_weights.tolist())\n",
    "    rr_data_dict[\"patristic_distance\"].extend(patristic_distances.tolist())\n",
    "\n",
    "response_regulator_df = pd.DataFrame(rr_data_dict)\n",
    "response_regulator_df = response_regulator_df.query(\"query != target\").reset_index(drop=True)\n",
    "response_regulator_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b1528f",
   "metadata": {},
   "source": [
    "We'll analyze the relationship between sequence weights and patristic distance with a simple linear regression. We'll frame the problem to directly assess the explanatory power of the model's sequence weights: how well do they explain the patristic distance to the query?\n",
    "\n",
    "For each query $q$ and each target sequence $i$ in the MSA, let's define our model as:\n",
    "\n",
    "$$\n",
    "d_{i} = \\beta_1^{(l)} w_{i}^{(l)} + \\beta_0^{(l)}\n",
    "$$ {#eq-scalar-regression}\n",
    "\n",
    "where $d_{i}$ is the patristic distance from the query $q$ to the target sequence $i$, $w_{i}^{(l)}$ is the normalized sequence weight assigned to sequence $i$ by a specific layer $l$, and $\\beta_1^{(l)}$ and $\\beta_0^{(l)}$ are the slope and intercept for the regression at layer $l$.\n",
    "\n",
    "Let's perform this regression independently for each of the three queries. For each query, we'll calculate the fit using the median weight across all layers and also for each of the 22 layers individually.\n",
    "\n",
    "We'll use the coefficient of determination ($R^2$) as the key statistic to measure the proportion of the variance in patristic distance that is explainable from the sequence weights. The following code calculates these regression statistics and generates an interactive plot to explore the relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | label: fig-rr-interactive\n",
    "# | fig-cap: An interactive display illustrating sequence weight versus patristic distance for each MSA member to the query. Each subplot represents the sequence weights relative to a different query. The dropdown controls which layer the sequence weights are from. By default, the median sequence weights across all layers are visualized. Black lines indicate the lines of best fit.\n",
    "\n",
    "import arcadia_pycolor as apc\n",
    "from analysis.plotting import interactive_layer_weight_plot\n",
    "\n",
    "regression_data = dict(\n",
    "    query=[],\n",
    "    layer=[],\n",
    "    r_squared=[],\n",
    "    p_value=[],\n",
    "    slope=[],\n",
    "    intercept=[],\n",
    ")\n",
    "\n",
    "for query in queries_list:\n",
    "    query_data = response_regulator_df[response_regulator_df[\"query\"] == query]\n",
    "    y = query_data[\"patristic_distance\"].values\n",
    "    x = query_data[\"median_weight\"].values\n",
    "    result = linregress(x, y)\n",
    "    regression_data[\"query\"].append(query)\n",
    "    regression_data[\"layer\"].append(\"median\")\n",
    "    regression_data[\"r_squared\"].append(result.rvalue**2)\n",
    "    regression_data[\"p_value\"].append(result.pvalue)\n",
    "    regression_data[\"slope\"].append(result.slope)\n",
    "    regression_data[\"intercept\"].append(result.intercept)\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        weight_col = f\"layer_{layer_idx}_weight\"\n",
    "        x = query_data[weight_col].values\n",
    "        result = linregress(x, y)\n",
    "        regression_data[\"query\"].append(query)\n",
    "        regression_data[\"layer\"].append(layer_idx)\n",
    "        regression_data[\"r_squared\"].append(result.rvalue**2)\n",
    "        regression_data[\"p_value\"].append(result.pvalue)\n",
    "        regression_data[\"slope\"].append(result.slope)\n",
    "        regression_data[\"intercept\"].append(result.intercept)\n",
    "\n",
    "rr_regression_df = pd.DataFrame(regression_data)\n",
    "rr_regression_df\n",
    "\n",
    "apc.plotly.setup()\n",
    "interactive_layer_weight_plot(response_regulator_df, rr_regression_df, rr_queries, subfamily_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60489b37",
   "metadata": {},
   "source": [
    "When viewing the median sequence weights in @fig-rr-interactive, we observe a negative correlation with patristic distance across all three subfamilies. This provides quantitative support for the original paper's central claim: on average, the model effectively learns to upweight evolutionarily closer sequences and downweight more distant ones.\n",
    "\n",
    "However, the layer-by-layer analysis uncovers a more nuanced and specialized division of labor. The strength, and even the direction, of this correlation varies---sometimes dramatically---with network depth. Some layers, such as layer 11, act as powerful phylogenetic filters. They exhibit a strong negative correlation ($R^2 > 0.6$ in some cases), sharply penalizing sequences as their evolutionary distance from the query increases. Other layers show weak or even positive correlations. Layer 12, for instance, behaves inconsistently. When GerE is the query, it slightly upweights more distant sequences, suggesting it has learned a feature representation that is either independent of, or runs counter to, simple phylogenetic distance.\n",
    "\n",
    "The model as a whole successfully captures a significant proportion of evolutionary relatedness, however this complex task is not distributed uniformly. Instead, specific layers appear to specialize in learning the phylogenetic structure of the MSA, while others focus on capturing different kinds of sequence information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe6650",
   "metadata": {},
   "source": [
    "## A survey across the tree of life\n",
    "\n",
    "Our analysis shows that median sequence weights correlate moderately with phylogenetic distance. More intriguingly, this layer-by-layer view has given us a peek behind the curtain, revealing a complex division of labor in how the model's attention mechanism captures evolutionary relatedness through the query-biased outer product.\n",
    "\n",
    "We want to further characterize MSA Pairformer's understanding of evolutionary relationships more broadly, so let's expand our analysis to thousands of diverse protein families.\n",
    "\n",
    "To do this, we turn to the OpenProteinSet [@Ahdritz2023], a massive public database of protein alignments. This resource, derived from UniClust30 and [hosted on AWS](https://registry.opendata.aws/openfold/), provides the scale we need to move beyond our single case study.\n",
    "\n",
    "Inferring phylogenetic trees for all ~270,000 UniClust30 MSAs in the collection would require roughly 10 times the amount of patience most people possess. Furthermore, some of these MSAs would be unsuitable for our analysis for one reason or another. So to whittle this down to a more digestable size, we'll create the following procedure.\n",
    "\n",
    ":::{.callout-note title=\"MSA pre-processing workflow\"}\n",
    "\n",
    "First, randomly select 20,000 MSAs from the UniClust30 collection. Then, for each of the 20,000 MSAs, apply the following procedure:\n",
    "\n",
    "- Select a diverse subset of up to 1024 sequences from the MSA\n",
    "    - Do this with the [MSA Pairformer API](https://github.com/yoakiyama/MSA_Pairformer/blob/33083d027788ee4a4295b554e782559b87e58fe5/MSA_Pairformer/dataset.py#L251-L276), which implements the sampling procedure introduced in MSA Transformer [@Rao2021]\n",
    "- Apply several filters that if the MSA does not pass, is discarded:\n",
    "    - Too shallow (fewer than 200 sequences), posing overfitting issues for downstream modelling (more on that later).\n",
    "    - Too long (over 1024 residues), posing computational constraints.\n",
    "    - Contains duplicate sequence identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Implementation of the workflow\n",
    "# | output: false\n",
    "import random\n",
    "\n",
    "from analysis.open_protein_set import fetch_all_ids, fetch_msas\n",
    "from analysis.sequence import write_processed_msa\n",
    "from analysis.utils import progress\n",
    "\n",
    "uniclust30_dir = Path(\"data\") / \"uniclust30\"\n",
    "uniclust30_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "msa_ids_path = uniclust30_dir / \"ids\"\n",
    "msa_ids = fetch_all_ids(cache_file=msa_ids_path)\n",
    "\n",
    "random.seed(42)\n",
    "msa_ids_subset = random.sample(msa_ids, k=20000)\n",
    "\n",
    "uniclust30_raw_msa_dir = uniclust30_dir / \"raw_msas\"\n",
    "uniclust30_raw_msa_dir.mkdir(exist_ok=True)\n",
    "\n",
    "raw_msa_paths = fetch_msas(msa_ids_subset, db_dir=uniclust30_raw_msa_dir)\n",
    "\n",
    "max_seq_length = 1024\n",
    "min_sequences = 200\n",
    "\n",
    "uniclust30_msa_dir = uniclust30_dir / \"msas\"\n",
    "uniclust30_msa_dir.mkdir(exist_ok=True)\n",
    "\n",
    "skipped_file = uniclust30_dir / \"skipped_ids\"\n",
    "if skipped_file.exists():\n",
    "    skipped_set = set(skipped_file.read_text().strip().split(\"\\n\"))\n",
    "else:\n",
    "    skipped_set = set()\n",
    "\n",
    "for id, raw_msa_path in progress(raw_msa_paths.items(), desc=\"Processing MSAs\"):\n",
    "    msa_path = uniclust30_msa_dir / f\"{id}.a3m\"\n",
    "\n",
    "    if msa_path.exists():\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    if id in skipped_set:\n",
    "        continue\n",
    "\n",
    "    msa = MSA(\n",
    "        raw_msa_path,\n",
    "        max_seqs=1024,\n",
    "        max_length=max_seq_length + 1,\n",
    "        diverse_select_method=\"hhfilter\",\n",
    "        secondary_filter_method=\"greedy\",\n",
    "    )\n",
    "\n",
    "    # Skip MSAs containing duplicate deflines. This likely occurs when multi-domain proteins\n",
    "    # generate multiple alignment hits. Duplicate names would cause tree construction to fail.\n",
    "    deflines = [msa.ids_l[idx] for idx in msa.select_diverse_indices]\n",
    "    if len(set(deflines)) != len(deflines):\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # We simplify verbose deflines from format tr|A0A1V5V6X5|LONG_SUFFIX to just A0A1V5V6X5.\n",
    "    # In rare cases (~0.5% of MSAs), simplification creates duplicates when both a consensus\n",
    "    # sequence (tr|ID|ID_consensus) and its non-consensus counterpart (tr|ID|ID_SPECIES)\n",
    "    # are present in the alignment. Rather than handle this edge case, we skip these MSAs.\n",
    "    simplified_deflines = [defline.split(\"|\")[1] for defline in deflines]\n",
    "    if len(set(simplified_deflines)) != len(simplified_deflines):\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # Skip MSAs exceeding maximum sequence length due to memory constraints\n",
    "    if msa.select_diverse_msa.shape[1] > max_seq_length:\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # Skip MSAs with too few sequences to avoid overfitting when modeling\n",
    "    # patristic distance with all 22 sequence weights.\n",
    "    if msa.select_diverse_msa.shape[0] < min_sequences:\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # Write processed MSA to A3M format\n",
    "    write_processed_msa(msa, msa_path, format=\"a3m\", simplify_ids=True)\n",
    "\n",
    "_ = skipped_file.write_text(\"\\n\".join(skipped_set) + \"\\n\")\n",
    "\n",
    "msas = {}\n",
    "for msa_path in progress(sorted(uniclust30_msa_dir.glob(\"*.a3m\")), desc=\"Loading MSAs\"):\n",
    "    msas[msa_path.stem] = MSA(msa_path, diverse_select_method=\"none\")\n",
    "\n",
    "print(f\"Final MSA count: {len(msas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad6b01",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "Like before, we calculate a tree and sequence weights for each MSA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6bbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating phylogenies\n",
    "# | output: false\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "from analysis.tree import run_fasttree_async\n",
    "\n",
    "uniclust30_tree_dir = uniclust30_dir / \"trees\"\n",
    "uniclust30_tree_dir.mkdir(exist_ok=True)\n",
    "\n",
    "jobs = []\n",
    "semaphore = asyncio.Semaphore(os.cpu_count() - 1)\n",
    "for a3m_path in uniclust30_msa_dir.glob(\"*.a3m\"):\n",
    "    fasttree_path = uniclust30_tree_dir / f\"{a3m_path.stem}.fasttree.newick\"\n",
    "    log_path = uniclust30_tree_dir / f\"{a3m_path.stem}.fasttree.log\"\n",
    "    if fasttree_path.exists():\n",
    "        continue\n",
    "\n",
    "    jobs.append(run_fasttree_async(a3m_path, fasttree_path, log_path, semaphore))\n",
    "\n",
    "_ = await asyncio.gather(*jobs)\n",
    "\n",
    "\n",
    "trees = {}\n",
    "for tree_path in progress(\n",
    "    sorted(uniclust30_tree_dir.glob(\"*.fasttree.newick\")),\n",
    "    desc=\"Loading trees\",\n",
    "):\n",
    "    id = tree_path.name.split(\".\")[0]\n",
    "    trees[id] = read_newick(tree_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating sequence weights\n",
    "from analysis.pairformer import calculate_sequence_weights\n",
    "\n",
    "seq_weights_path = uniclust30_dir / \"seq_weights.pt\"\n",
    "\n",
    "# When running on Modal, calculate_sequence_weights serializes MSAs to send to remote GPU workers.\n",
    "# Serializing all MSAs at once exceeds Modal's serialization limits, so we batch into groups\n",
    "# of 1000. This constraint is specific to Modal's RPC layer. This batching choice is unnecessary\n",
    "# yet harmless for local execution.\n",
    "seq_weights = {}\n",
    "batch_size = 1000\n",
    "\n",
    "_msa_items = list(msas.items())\n",
    "\n",
    "if seq_weights_path.exists():\n",
    "    seq_weights = torch.load(seq_weights_path, weights_only=True)\n",
    "else:\n",
    "    for batch_start in progress(\n",
    "        range(0, len(_msa_items), batch_size), desc=\"Calculating sequence weights\"\n",
    "    ):\n",
    "        _batch_msas = dict(_msa_items[batch_start : batch_start + batch_size])\n",
    "        _batch_weights = calculate_sequence_weights(_batch_msas)\n",
    "        seq_weights.update(_batch_weights)\n",
    "\n",
    "    torch.save(seq_weights, seq_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51754b",
   "metadata": {},
   "source": [
    ":::{.callout-note title=\"For those following at home\" collapse=\"true\"}\n",
    "After running the above computations, you'll have the primary data in the following directories:\n",
    "\n",
    "* MSAs: `data/uniclust30/msas`\n",
    "* trees: `data/uniclust30/trees`\n",
    "* sequence weights: `data/uniclust30/seq_weights.pt`\n",
    "\n",
    "These data could be a prime launch point for followup studies.\n",
    ":::\n",
    "\n",
    "## Explanatory model across all layers\n",
    "\n",
    "In @fig-rr-interactive, we performed separate linear regressions for each layer, illustrating the explanatory power of each layer in isolation. Now, with thousands of MSAs, we can graduate to a more comprehensive question. Instead of asking how well *a single layer* predicts evolutionary distance, we ask:\n",
    "\n",
    ":::{.callout-tip title=\"Key Question\"}\n",
    "How well do sequence weights from all 22 layers, when used *jointly*, predict phylogenetic distance?\n",
    ":::\n",
    "\n",
    "In posing this question, we must be clear about our goal: we're interested in assessing explanatory power of these sequence weights, not predictive power. In otherwords, we're using these regressions as a way to quantify the *in-sample*[^insample] explanatory power of the model's complete set of sequence weights.\n",
    "\n",
    "Mathematically, we define a weight vector $\\mathbf{w}_i$ for each sequence $i$, which is composed of the weights from all $L$ layers. Our model then finds the single coefficient vector $\\boldsymbol{\\beta}$ that best maps these weights to the patristic distance $d_i$:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_i = \\begin{bmatrix} w_i^{(1)} \\\\ w_i^{(2)} \\\\ \\vdots \\\\ w_i^{(L)} \\end{bmatrix} \\quad \\text{and} \\quad d_i = \\boldsymbol{\\beta}^T \\mathbf{w}_i + \\beta_0\n",
    "$$\n",
    "\n",
    "Since we're using 22 predictors $(k=22)$ and our MSAs have varying number of sequences $(N)$, we risk overfitting when $N$ is low. We mitigate this risk by filtering MSAs with less than 200 sequences, so that our shallowest MSAs yield an observation to parameter ratio of around 10:1. Furthermore, we score goodness-of-fit using adjusted $R^2$ $(R^2_\\text{adj})$ instead of $R^2$, which penalizes scores for MSAs with low depth[^adjr2].\n",
    "\n",
    "Let's calculate these regressions and plot the results.\n",
    "\n",
    "[^insample]: \"In-sample\" analysis evaluates a model using the same dataset that was used to fit its parameters. The goal is to measure goodness-of-fit, i.e., how well the model describes the data it was built from. This contrasts with \"out-of-sample\" analysis, which would use a separate, \"held-out\" dataset to assess predictive power and the model's ability to generalize.\n",
    "\n",
    "[^adjr2]: Adjusted $R^2$ is defined as $R^2_{\\text{adj}} = 1 - (1 - R^2)\\frac{n - 1}{n - p - 1}$, which corrects $R^2$ for the number of predictors $p$ and sample size $n$, thereby penalizing overparameterized models and providing an unbiased estimate of explained variance. Learn more [here](https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Running a linear regression on each MSA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from analysis.regression import regress_and_analyze_features\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def process_msa(query: str, query_length: int, dist_to_query: np.ndarray, weights: torch.Tensor) -> dict[str, Any]:\n",
    "    data = {}\n",
    "\n",
    "    # Regress the sequence weights against patristic distance.\n",
    "    # Perform an ANOVA (type III) to establish explanatory importance\n",
    "    # of each layer's sequence weights.\n",
    "    model, anova_table = regress_and_analyze_features(weights, dist_to_query)\n",
    "\n",
    "    data[\"Query\"] = query\n",
    "    data[\"MSA Depth\"] = len(dist_to_query)\n",
    "    data[\"MSA Length\"] = query_length\n",
    "    data[\"R2\"] = model.rsquared\n",
    "    data[\"Adjusted R2\"] = model.rsquared_adj\n",
    "    data.update(anova_table[\"percent_sum_sq\"].to_dict())\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "jobs = []\n",
    "for query in seq_weights.keys():\n",
    "    msa = msas[query]\n",
    "    tree = trees[query]\n",
    "    weights = seq_weights[query]\n",
    "\n",
    "    query_len = msa.select_diverse_msa.shape[1]\n",
    "\n",
    "    size = len(tree.get_leaf_names())\n",
    "    if size < 200:\n",
    "        continue\n",
    "\n",
    "    dist_to_query = get_patristic_distance(tree, query)[msa.ids_l].values\n",
    "    jobs.append(delayed(process_msa)(query, query_len, dist_to_query, weights))\n",
    "\n",
    "results_df = pd.DataFrame(Parallel(-1)(jobs))\n",
    "results_df.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Plotting the results\n",
    "# | label: fig-ridgeline\n",
    "# | fig-cap: Overview of linear regression performance, when binning MSAs by depth (number of sequences). (Left) A barplot showing the number of MSAs found in each bin. (Right) Density plots showing the distribution of $R^2_\\text{adj}$ within each bin. Hovering over each distribution reveals its mean and standard deviation.\n",
    "from analysis.plotting import ridgeline_r2_plot\n",
    "\n",
    "ridgeline_r2_plot(results_df, gradient=apc.gradients.verde.reverse(), gap=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb7c69",
   "metadata": {},
   "source": [
    "@fig-ridgeline provides a high-level overview of MSA Pairformer's ability to explain phylogenetic distance via the query-biased outer product sequence weights, across thousands of MSAs. The left panel presents a bar chart indicating the distribution of MSA depths in our dataset. We observe progressively fewer MSAs in bins of increasing depth, except for the final bin (900-1024 sequences), which occurs due to an artifact of our preprocessing, whereby MSAs with more than 1024 sequences are subset to 1024 sequences. Critically, each bin contains hundreds of MSAs, allowing for a robust statistical comparison across bins. The right panel illustrates the distribution of $R^2_\\text{adj}$ values for each MSA depth bin. Two key observations stand out.\n",
    "\n",
    "First, the distributions are remarkably stable across all depth bins, suggesting that the model's joint sequence weights are largely independent of MSA depth. We explore this statistically in the collapsable section below.\n",
    "\n",
    "Second, contrary to the between-group variation, the within-group variation is substantial. Each distribution is broad, spanning a wide range of $R^2_\\text{adj}$ values. This indicates that while average performance is consistent, the model's ability to explain phylogenetic distance varies dramatically from one MSA to another, even for MSAs of similar size.\n",
    "\n",
    ":::{.callout-note title=\"Click to reveal supplementary statistical tests\" collapse=\"true\"}\n",
    "\n",
    "To statistically validate the visual impression from @fig-ridgeline---that MSA depth does not substantially relate to model performance ($R^2_{adj}$)---we perform two tests. First, we use a one-way ANOVA to check for significant differences between the binned MSA depth groups. Second, because binning can introduce arbitrary boundaries, we also run a linear regression to test the direct relationship between $R^2_{adj}$ and MSA depth as a continuous variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc773002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from analysis.utils import console\n",
    "from rich.table import Table\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "bin_edges = [200, 300, 400, 500, 600, 700, 800, 900, 1025]\n",
    "bin_labels = [\n",
    "    \"200-299\",\n",
    "    \"300-399\",\n",
    "    \"400-499\",\n",
    "    \"500-599\",\n",
    "    \"600-699\",\n",
    "    \"700-799\",\n",
    "    \"800-899\",\n",
    "    \"900-1024\",\n",
    "]\n",
    "\n",
    "results_df[\"MSA Depth Bin\"] = pd.cut(results_df[\"MSA Depth\"], bins=bin_edges, labels=bin_labels, right=False)\n",
    "\n",
    "# One-way ANOVA (binned MSA Depth)\n",
    "aov_model = ols('Q(\"Adjusted R2\") ~ C(Q(\"MSA Depth Bin\"))', data=results_df).fit()\n",
    "aov = sm.stats.anova_lm(aov_model, typ=2)\n",
    "F = aov.loc['C(Q(\"MSA Depth Bin\"))', 'F']\n",
    "p_aov = aov.loc['C(Q(\"MSA Depth Bin\"))', 'PR(>F)']\n",
    "eta2 = aov.loc['C(Q(\"MSA Depth Bin\"))', 'sum_sq'] / (\n",
    "    aov.loc['C(Q(\"MSA Depth Bin\"))', 'sum_sq'] + aov.loc['Residual', 'sum_sq']\n",
    ")\n",
    "\n",
    "lm = smf.ols('Q(\"Adjusted R2\") ~ Q(\"MSA Depth\")', data=results_df).fit()\n",
    "slope = lm.params['Q(\"MSA Depth\")']\n",
    "intercept = lm.params[\"Intercept\"]\n",
    "p_slope = lm.pvalues['Q(\"MSA Depth\")']\n",
    "t_slope = lm.tvalues['Q(\"MSA Depth\")']\n",
    "r2 = lm.rsquared\n",
    "r2_adj = lm.rsquared_adj\n",
    "nobs = int(lm.nobs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(\n",
    "    results_df[\"MSA Depth\"],\n",
    "    results_df[\"Adjusted R2\"],\n",
    "    alpha=0.1,\n",
    "    s=15,\n",
    "    color=apc.black.hex_code,\n",
    "    edgecolors=\"none\",\n",
    ")\n",
    "\n",
    "predictions = lm.get_prediction(results_df[[\"MSA Depth\"]])\n",
    "prediction_summary = predictions.summary_frame(alpha=0.05)\n",
    "\n",
    "sort_idx = np.argsort(results_df[\"MSA Depth\"])\n",
    "x_sorted = results_df[\"MSA Depth\"].iloc[sort_idx]\n",
    "y_pred = prediction_summary[\"mean\"].iloc[sort_idx]\n",
    "ci_lower = prediction_summary[\"mean_ci_lower\"].iloc[sort_idx]\n",
    "ci_upper = prediction_summary[\"mean_ci_upper\"].iloc[sort_idx]\n",
    "\n",
    "ax.fill_between(\n",
    "    x_sorted,\n",
    "    ci_lower,\n",
    "    ci_upper,\n",
    "    alpha=0.2,\n",
    "    color=apc.black.hex_code,\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    x_sorted,\n",
    "    y_pred,\n",
    "    color=apc.black.hex_code,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"MSA depth\")\n",
    "ax.set_ylabel(\"Adjusted R²\")\n",
    "apc.mpl.style_plot(ax, monospaced_axes=\"both\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"One-way ANOVA on Adjusted R² across MSA Depth Bins\")\n",
    "print(\"=\"*60)\n",
    "print(f\"F-statistic:        {F:.2f}\")\n",
    "print(f\"p-value:            {p_aov:.3e}\")\n",
    "print(f\"Effect size (η²):   {eta2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Linear Regression: Adjusted R² ~ MSA Depth\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Intercept:          {intercept:.6g}\")\n",
    "print(f\"Slope:              {slope:.6g}\")\n",
    "print(f\"t-stat (slope):     {t_slope:.4g}\")\n",
    "print(f\"p-value (slope):    {p_slope}\")\n",
    "print(f\"R²:                 {r2:.4f}\")\n",
    "print(f\"Adj. R²:            {r2_adj:.4f}\")\n",
    "print(f\"N:                  {nobs}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a195ce8",
   "metadata": {},
   "source": [
    "While both tests return highly significant p-values, the associated effect sizes are negligible (explaining $<2\\%$ and $<1\\%$ of the variance in $R^2_{adj}$, respectively).\n",
    "\n",
    ":::\n",
    "\n",
    "## MSA Pairformer's division of labor\n",
    "\n",
    "@fig-ridgeline reveals a high-level picture: the joint explanatory power of all 22 layers is robust to MSA depth but highly variable from one MSA to the next. In our initial case study (@fig-rr-interactive), we saw a \"division of labor,\" where specific layers (like layer 11) acted as powerful phylogenetic filters. Now, with thousands of MSAs, we can (a) further characterize this division of labor and (b) determine how it may vary depending on MSA characteristics.\n",
    "\n",
    "To investigate this, we study the individual explanatory power of each layer, calculated via an ANOVA. This allows us to quantify each layer's feature importance (as a percentage of the total sum of squares explained) and see how this internal strategy shifts. First, let's see if the layer importance profile changes with MSA depth in @fig-importance-depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fe87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | label: fig-importance-depth\n",
    "# | fig-cap: Average feature importance (percent of total sum of squares explained) for each of the 22 layers, binned by MSA depth.\n",
    "from analysis.plotting import stacked_feature_importance_plot\n",
    "\n",
    "stacked_feature_importance_plot(\n",
    "    results_df,\n",
    "    bin_col=\"MSA Depth\",\n",
    "    bin_edges=[200, 300, 400, 500, 600, 700, 800, 900, 1025],\n",
    "    bin_display_name=\"MSA depth\",\n",
    "    bin_labels=[\"200-299\", \"300-399\", \"400-499\", \"500-599\", \"600-699\", \"700-799\", \"800-899\", \"900-1024\"],\n",
    "    gradient=apc.gradients.verde.reverse(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4b214",
   "metadata": {},
   "source": [
    "@fig-importance-depth plots the average feature importance profile for each MSA depth bin. The most immediate finding is that these profiles are remarkably consistent across all bins. The model's \"average\" strategy for parsing phylogenetic information appears largely independent of MSA size. This figure also confirms our \"division of labor\" hypothesis on a much larger scale. The contributions are far from uniform:\n",
    "\n",
    "* Layer 11 consistently dominates, single-handedly accounting for ~15% of the explained variance.\n",
    "* The first 10 layers all make consistent, nominal contributions.\n",
    "* The final layers' contributions are diminished, particularly those of layers 18 and 20.\n",
    "\n",
    "This suggests the model has a \"default\" strategy for this task. However, this consistent average strategy doesn't explain the significant variance in performance we saw in @fig-ridgeline. What internal strategies are associated with very high (or very low) performance?\n",
    "\n",
    "To answer this, @fig-importance-r2 bins the MSAs not by depth, but by their explanatory power ($R^2_\\text{adj}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | label: fig-importance-r2\n",
    "# | fig-cap: Average feature importance (percent of total sum of squares explained) for each of the 22 layers, binned by explanatory power $R^2_\\text{adj}$.\n",
    "\n",
    "import seaborn as sns\n",
    "from analysis.plotting import gradient_from_listed_colormap\n",
    "\n",
    "flare_gradient = gradient_from_listed_colormap(sns.color_palette(\"flare\", as_cmap=True), \"flare\")\n",
    "purple_gradient = gradient_from_listed_colormap(sns.cubehelix_palette(as_cmap=True), \"purple\")\n",
    "stacked_feature_importance_plot(\n",
    "    results_df,\n",
    "    bin_col=\"Adjusted R2\",\n",
    "    bin_edges=[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    bin_display_name=\"Adjusted R²\",\n",
    "    annotation_y_position=0.70,\n",
    "    gradient=purple_gradient,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8ac0",
   "metadata": {},
   "source": [
    "Compared to @fig-importance-depth, the story in @fig-importance-r2 is strikingly different. Instead of stable profiles seen across MSA depths, binning by performance reveals a strong correlation between MSA Pairformer's sequence weight profile for the MSA and its explanatory success.\n",
    "\n",
    "In cases of low explanatory success (e.g., $R^2_\\text{adj} < 0.6$), we see MSAs with substantial contributions from layer 7, which for the lowest MSA depth bin matches the normally-dominant layer 11. As performance improves into the intermediate range ($R^2_\\text{adj} \\approx 0.6 - 0.8$), the strategy reverts to the \"default\" sequence weight profile we saw in @fig-importance-depth. \n",
    "\n",
    "Most interestingly, MSAs with the highest explanatory success ($R^2_\\text{adj} > 0.8$) have disproportionately high contributions from layer 13, and down-weighted importance of layer 11. The relative importance of layer 13 grows steadily with increasing explanatory success, reaching up to 15% in the highest performing bin.\n",
    "\n",
    "These patterns demonstrates that the \"division of labor\" is not fixed. The model responds to different MSAs by producing different sequence weight profiles. We find these distinct internal strategies, in turn, associate strongly with different levels of success in explaining phylogenetic distance.\n",
    "\n",
    "## The role of tree topology\n",
    "\n",
    "We've observed that MSA Pairformer's performance in explaining evolutionary relatedness (@fig-ridgeline) and its internal sequence weighting (@fig-importance-r2) vary significantly across MSAs. We hypothesize that these differences are driven by the phylogenetic tree topology of each alignment.\n",
    "\n",
    "Testing this hypothesis requires isolating topology from the confounding variable of tree size. As noted previously [@Janzen2024], topological statistics are difficult to normalize or compare across trees of different sizes.\n",
    "\n",
    "To control for this, we created a standardized dataset by downsampling all MSAs to a uniform depth of 200 sequences. This ensures tree size is constant, allowing us to attribute remaining performance differences to topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Downsampling trees and MSAs to depth 200\n",
    "from analysis.sequence import filter_msa_by_tree, write_fasta_like\n",
    "from analysis.tree import write_newick\n",
    "\n",
    "uniclust30_msa_depth_200_dir = uniclust30_dir / \"msas_depth_200\"\n",
    "uniclust30_msa_depth_200_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "uniclust30_trees_depth_200_dir = uniclust30_dir / \"trees_depth_200\"\n",
    "uniclust30_trees_depth_200_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "msas_depth_200 = {}\n",
    "trees_depth_200 = {}\n",
    "\n",
    "for query, msa in progress(msas.items()):\n",
    "    tree = trees[query]\n",
    "    if len(tree.get_leaf_names()) < 200:\n",
    "        continue\n",
    "\n",
    "    msa_depth_200_path = uniclust30_msa_depth_200_dir / f\"{query}.a3m\"\n",
    "    tree_depth_200_path = uniclust30_trees_depth_200_dir / f\"{query}.fasttree.newick\"\n",
    "\n",
    "    if not msa_depth_200_path.exists() or not tree_depth_200_path.exists():\n",
    "        tree_subset = subset_tree(tree, n=200, force_include=[query], seed=42)\n",
    "        write_fasta_like(*filter_msa_by_tree(msa, tree_subset), msa_depth_200_path)\n",
    "        write_newick(tree_subset, tree_depth_200_path)\n",
    "\n",
    "    msas_depth_200[query] = MSA(msa_depth_200_path, diverse_select_method=\"none\")\n",
    "    trees_depth_200[query] = read_newick(tree_depth_200_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating sequence weights\n",
    "seq_weights_depth_200_path = uniclust30_dir / \"seq_weights_depth_200.pt\"\n",
    "\n",
    "# When running on Modal, calculate_sequence_weights serializes MSAs to send to remote GPU workers.\n",
    "# Serializing all MSAs at once exceeds Modal's serialization limits, so we batch into groups\n",
    "# of 1000. This constraint is specific to Modal's RPC layer. This batching choice is unnecessary\n",
    "# yet harmless for local execution.\n",
    "seq_weights_depth_200 = {}\n",
    "batch_size = 1000\n",
    "\n",
    "_msa_items = list(msas_depth_200.items())\n",
    "\n",
    "if seq_weights_depth_200_path.exists():\n",
    "    seq_weights_depth_200 = torch.load(seq_weights_depth_200_path, weights_only=True)\n",
    "else:\n",
    "    for batch_start in progress(\n",
    "        range(0, len(_msa_items), batch_size), desc=\"Calculating sequence weights\"\n",
    "    ):\n",
    "        _batch_msas = dict(_msa_items[batch_start : batch_start + batch_size])\n",
    "        _batch_weights = calculate_sequence_weights(_batch_msas)\n",
    "        seq_weights_depth_200.update(_batch_weights)\n",
    "\n",
    "    torch.save(seq_weights_depth_200, seq_weights_depth_200_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697e8cb",
   "metadata": {},
   "source": [
    "To characterize tree shape, we use a combination of global tree metrics, as well as query-centric metrics.\n",
    "\n",
    "| Category | Metric | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| **Global** | Phylogenetic diversity | The sum of all branch lengths in the tree. |\n",
    "| **Global** | Colless index | A measure of tree imbalance, calculated as the sum of the absolute differences in the number of tips descending from the left and right children of each internal node. |\n",
    "| **Global** | Cherry count | The total number of \"cherries,\" which are pairs of leaves that share an immediate common ancestor. |\n",
    "| **Global** | Ultrametricity CV | The coefficient of variation (standard deviation / mean) of the root-to-tip distances. A value of 0 indicates a perfectly ultrametric tree. |\n",
    "| **Query-Centric** | Patristic standard deviation | The standard deviation of the patristic distances (the sum of branch lengths on the shortest path) from the query sequence to all other leaves. |\n",
    "| **Query-Centric** | Query centrality | Measures the query's position relative to the rest of the tree. Calculated as the ratio of the mean distance from the query to all leaves divided by the mean pairwise distance of all leaves. Values < 1 indicate a central position. |\n",
    "\n",
    ": A summary of global and query-centric metrics used to characterize phylogenetic tree topology. {#tbl-topology-metrics tbl-colwidths=\"[25,25,50]\" tbl-cap-location=\"bottom\"}\n",
    "\n",
    "For our global metrics, we adapt recommendations from [@Janzen2024]. We also add *Ultrametricity CV* to quantify how clock-like the tree is, hypothesizing that variation in root-to-tip distances may affect the model's learning of evolutionary rates.\n",
    "\n",
    "Since global metrics are blind to the query's position---the anchor for the model's attention---we also introduce two query-entric metrics. *Patristic standard deviation* measures the spread of evolutionary distances from the query, while *Query centrality* assesses whether the query is topologically central or peripheral. We can now investigate how this full set of features correlates with the model's explanatory success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating regressions and tree statistics\n",
    "# | output: false\n",
    "\n",
    "import pandas as pd\n",
    "from analysis.regression import regress_and_analyze_features\n",
    "from analysis.tree import (\n",
    "    cherry_count_statistic,\n",
    "    colless_statistic,\n",
    "    patristic_std,\n",
    "    phylogenetic_diversity_statistic,\n",
    "    query_centrality,\n",
    "    ultrametricity_cv,\n",
    ")\n",
    "from ete3 import Tree\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def process_msa(query: str, dist_to_query: pd.Series, tree: Tree, weights: torch.Tensor) -> dict[str, Any]:\n",
    "    data = {}\n",
    "\n",
    "    num_seqs = len(dist_to_query)\n",
    "\n",
    "    # Regress the sequence weights against patristic distance.\n",
    "    # Perform an ANOVA (type III) to establish explanatory importance\n",
    "    # of each layer's sequence weights.\n",
    "    model, anova_table = regress_and_analyze_features(weights, dist_to_query.values)\n",
    "\n",
    "    q1_dist_to_query = dist_to_query.sort_values()[:int(num_seqs // 4)]\n",
    "    q1_tree = tree.copy()\n",
    "    q1_tree.prune(q1_dist_to_query.index.to_list())\n",
    "\n",
    "    data[\"Query\"] = query\n",
    "    data[\"R2\"] = model.rsquared\n",
    "    data[\"Adjusted R2\"] = model.rsquared_adj\n",
    "\n",
    "    # Global metrics\n",
    "    data[\"Phylogenetic diversity\"] = phylogenetic_diversity_statistic(tree)\n",
    "    data[\"Colless\"] = colless_statistic(tree)\n",
    "    data[\"Cherry count\"] = cherry_count_statistic(tree)\n",
    "    data[\"Ultrametricity CV\"] = ultrametricity_cv(tree)\n",
    "\n",
    "    # Query-centric metrics\n",
    "    data[\"Patristic std\"] = patristic_std(tree, query)\n",
    "    data[\"Query centrality\"] = query_centrality(tree, query)\n",
    "\n",
    "    data.update(anova_table[\"percent_sum_sq\"].to_dict())\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "jobs = []\n",
    "for query in seq_weights_depth_200.keys():\n",
    "    msa = msas_depth_200[query]\n",
    "    tree = trees_depth_200[query]\n",
    "    weights = seq_weights_depth_200[query]\n",
    "\n",
    "    dist_to_query = get_patristic_distance(tree, query)[msa.ids_l]\n",
    "    jobs.append(delayed(process_msa)(query, dist_to_query, tree, weights))\n",
    "\n",
    "results_depth_200_df = pd.DataFrame(Parallel(-1)(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_depth_200_df[\"Distance gradient smoothness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d57ab",
   "metadata": {},
   "source": [
    "* Discuss streamlit app\n",
    "* Careful discussion about results\n",
    "* We can predict how well the sequence weights of an MSA will predict patristic distance based on two simple parameters: phylogenetic diversity and patristic Std.\n",
    "* However, the goal of the model isn't to predict phylogenetic diversity\n",
    "\n",
    "## Correspondence to downstream task success\n",
    "\n",
    "We've characterized how well sequence weights can be used to predict evolutionary distance, giving us insight into which MSAs the model is able to accurately characterize from an evolutionary context, and the MSAs that it can't.\n",
    "\n",
    "However, does this reflect real downstream performance?\n",
    "\n",
    "We'll test this with beta carbon contact prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Downloading/fetching PDBs\n",
    "from analysis.open_protein_set import fetch_pdbs\n",
    "\n",
    "pdb_dir = uniclust30_dir / \"pdbs\"\n",
    "pdb_paths = fetch_pdbs(msas_depth_200.keys(), pdb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating beta-carbon contacts from structures\n",
    "from analysis.structure import load_structure, split_structure_by_atom_type\n",
    "\n",
    "angstrom_cutoff = 8.0\n",
    "\n",
    "def euclidean_distance_tensor(coords: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.linalg.norm(coords[:, None, :] - coords[None, :, :], axis=-1)\n",
    "\n",
    "cb_contacts_pdb = {}\n",
    "for query, pdb_path in progress(pdb_paths.items(), desc=\"Calculating CB contacts\"):\n",
    "    _, cb_coords, _, _ = split_structure_by_atom_type(load_structure(pdb_path))\n",
    "    cb_dist = euclidean_distance_tensor(cb_coords)\n",
    "    cb_contacts_pdb[query] = cb_dist < angstrom_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Predicting beta-carbon contacts with MSA Pairformer\n",
    "\n",
    "from analysis.pairformer import calculate_cb_contacts\n",
    "\n",
    "cb_contacts_depth_200_path = uniclust30_dir / \"cb_contacts_depth_200.pt\"\n",
    "\n",
    "# When running on Modal, calculate_cb_contacts serializes MSAs to send to remote GPU workers.\n",
    "# Serializing all MSAs at once exceeds Modal's serialization limits, so we batch into groups\n",
    "# of 1000. This constraint is specific to Modal's RPC layer. This batching choice is unnecessary\n",
    "# yet harmless for local execution.\n",
    "cb_contacts_depth_200 = {}\n",
    "batch_size = 250\n",
    "\n",
    "_msa_items = list(msas_depth_200.items())\n",
    "\n",
    "if cb_contacts_depth_200_path.exists():\n",
    "    cb_contacts_depth_200 = torch.load(cb_contacts_depth_200_path, weights_only=True)\n",
    "else:\n",
    "    for batch_start in progress(\n",
    "        range(0, len(_msa_items), batch_size), desc=\"Predicting CB contacts\"\n",
    "    ):\n",
    "        _batch_msas = dict(_msa_items[batch_start : batch_start + batch_size])\n",
    "        _batch_cb_contacts = calculate_cb_contacts(_batch_msas)\n",
    "        cb_contacts_depth_200.update(_batch_cb_contacts)\n",
    "\n",
    "    torch.save(cb_contacts_depth_200, cb_contacts_depth_200_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.structure import calculate_long_range_p_at_l\n",
    "\n",
    "queries_with_missing_pdb_residues = []\n",
    "p_at_ls = {}\n",
    "for query in cb_contacts_depth_200.keys():\n",
    "    pred_scores = cb_contacts_depth_200[query].squeeze()\n",
    "    ground_truth = cb_contacts_pdb[query]\n",
    "\n",
    "    # Sometimes a residue is missing from the PDB structure,\n",
    "    # creating a mismatch in the shapes between ground truth\n",
    "    # and the prediction. We skip these rare instances.\n",
    "    if pred_scores.size(1) != ground_truth.size(1):\n",
    "        queries_with_missing_pdb_residues.append(query)\n",
    "        continue\n",
    "\n",
    "    p_at_ls[query] = calculate_long_range_p_at_l(\n",
    "        pred_scores=cb_contacts_depth_200[query].squeeze(),\n",
    "        ground_truth=cb_contacts_pdb[query],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_depth_200_df[\"P@L\"] = results_depth_200_df[\"Query\"].map(p_at_ls)\n",
    "results_depth_200_df.to_csv(\"test.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebc5e8",
   "metadata": {},
   "source": [
    "## Experimental stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env USE_MODAL=1\n",
    "\n",
    "from analysis.pairformer import calculate_cb_contacts\n",
    "\n",
    "ans = calculate_cb_contacts({\"Z4X668\": msas_depth_200[\"Z4X668\"]})\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.structure import calculate_long_range_p_at_l\n",
    "\n",
    "min_seq_sep = 24\n",
    "pred_scores = ans[\"Z4X668\"].squeeze(0)\n",
    "ground_truth = cb_contacts[\"Z4X668\"]\n",
    "\n",
    "calculate_long_range_p_at_l(pred_scores, ground_truth, min_seq_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.plotting import tree_style_with_highlights\n",
    "\n",
    "def visualize_tree(query):\n",
    "    tree_style_with_highlights\n",
    "    tree = trees_depth_200[query].copy()\n",
    "    display(tree.render(\"%%inline\", tree_style=tree_style_with_highlights([query])))\n",
    "\n",
    "def visualize_patristic_histogram(query):\n",
    "    tree = trees_depth_200[query].copy()\n",
    "    distances = get_patristic_distance(tree, query).values\n",
    "    plt.hist(distances, bins=30)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_layer_11_correlation(query):\n",
    "    tree = trees_depth_200[query].copy()\n",
    "    distances = get_patristic_distance(tree, query).values\n",
    "    weights = seq_weights_depth_200[query].clone()\n",
    "    plt.scatter(weights[:, 11], distances)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_var = results_depth_200_df.sort_values(\"Std patristic\", ascending=False)[\"Query\"][:5]\n",
    "for q in highest_var:\n",
    "    visualize_tree(q)\n",
    "    visualize_patristic_histogram(q)\n",
    "    visualize_layer_11_correlation(q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_var = results_depth_200_df.sort_values(\"Std patristic\", ascending=False)[\"Query\"][:5]\n",
    "for q in lowest_var:\n",
    "    visualize_tree(q)\n",
    "    visualize_patristic_histogram(q)\n",
    "    visualize_layer_11_correlation(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76039ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adj_r2 = results_depth_200_df.sort_values(\"Adjusted R2\", ascending=False)[\"Query\"][:20]\n",
    "for q in best_adj_r2:\n",
    "    visualize_tree(q)\n",
    "    visualize_patristic_histogram(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb33f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "2025-phylogenetic-analysis-of-msa-pairformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1daa3cc0ab3c4b3796c6acefe7b557c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "IntSliderView",
       "behavior": "drag-tap",
       "continuous_update": true,
       "description": "",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_ed663176de34431db45f0ed95d182d5c",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_87d610547c8d46b8a337cbed38da3e50",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "21bf29f5d21c4695b0b6c51aff6a1212": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39a59ea193e14707a8fad835b674c771": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "OrbitControlsModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "OrbitControlsModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "autoRotate": false,
       "autoRotateSpeed": 2,
       "controlling": "IPY_MODEL_efffc72c814b445bb3a9eac395e4bf2f",
       "dampingFactor": 0.25,
       "enableDamping": false,
       "enableKeys": true,
       "enablePan": true,
       "enableRotate": true,
       "enableZoom": true,
       "enabled": true,
       "keyPanSpeed": 7,
       "maxAzimuthAngle": "inf",
       "maxDistance": "inf",
       "maxPolarAngle": 3.141592653589793,
       "maxZoom": "inf",
       "minAzimuthAngle": "-inf",
       "minDistance": 0,
       "minPolarAngle": 0,
       "minZoom": 0,
       "panSpeed": 1,
       "rotateSpeed": 1,
       "screenSpacePanning": true,
       "target": [
        0,
        0,
        0
       ],
       "zoomSpeed": 1
      }
     },
     "39db96ed75d34ded998a770bf6293fcf": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "SceneModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "SceneModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "autoUpdate": true,
       "background": "#ffffff",
       "castShadow": false,
       "children": [
        "IPY_MODEL_91a6ea051c394649990df56ec3b14428",
        "IPY_MODEL_42a8ed88d63a4b25b0998b12e39d7959"
       ],
       "fog": null,
       "frustumCulled": true,
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "overrideMaterial": null,
       "position": [
        0,
        0,
        0
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "Scene",
       "up": [
        0,
        1,
        0
       ],
       "visible": true
      }
     },
     "3d6f1e15b70e45369a6d95ffcb38fdb8": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "RendererModel",
      "state": {
       "_alpha": false,
       "_antialias": false,
       "_dom_classes": [],
       "_height": 400,
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "RendererModel",
       "_pause_autorender": false,
       "_view_count": null,
       "_view_module": "jupyter-threejs",
       "_view_module_version": "^2.4.1",
       "_view_name": "RendererView",
       "_webgl_version": 2,
       "_width": 600,
       "autoClear": true,
       "autoClearColor": true,
       "autoClearDepth": true,
       "autoClearStencil": true,
       "background": "black",
       "background_opacity": 1,
       "camera": "IPY_MODEL_efffc72c814b445bb3a9eac395e4bf2f",
       "clearColor": "#000000",
       "clearOpacity": 1,
       "clippingPlanes": [],
       "controls": [
        "IPY_MODEL_39a59ea193e14707a8fad835b674c771"
       ],
       "gammaFactor": 2,
       "gammaInput": false,
       "gammaOutput": false,
       "layout": "IPY_MODEL_21bf29f5d21c4695b0b6c51aff6a1212",
       "localClippingEnabled": false,
       "maxMorphNormals": 4,
       "maxMorphTargets": 8,
       "physicallyCorrectLights": false,
       "scene": "IPY_MODEL_39db96ed75d34ded998a770bf6293fcf",
       "shadowMap": "IPY_MODEL_78db84fa486848f686977f93545f809a",
       "sortObject": true,
       "tabbable": null,
       "toneMapping": "LinearToneMapping",
       "toneMappingExposure": 1,
       "toneMappingWhitePoint": 1,
       "tooltip": null
      }
     },
     "42a8ed88d63a4b25b0998b12e39d7959": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "AmbientLightModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "AmbientLightModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "castShadow": false,
       "children": [],
       "color": "#ffffff",
       "frustumCulled": true,
       "intensity": 1,
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "position": [
        0,
        0,
        0
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "AmbientLight",
       "up": [
        0,
        1,
        0
       ],
       "visible": true
      }
     },
     "593f1acdace644399853d7760aeaa4d7": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "PointsMaterialModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "PointsMaterialModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "alphaTest": 0,
       "blendDst": "OneMinusSrcAlphaFactor",
       "blendDstAlpha": 0,
       "blendEquation": "AddEquation",
       "blendEquationAlpha": 0,
       "blendSrc": "SrcAlphaFactor",
       "blendSrcAlpha": 0,
       "blending": "NormalBlending",
       "clipIntersection": false,
       "clipShadows": false,
       "clippingPlanes": [],
       "color": "#ffffff",
       "colorWrite": true,
       "defines": null,
       "depthFunc": "LessEqualDepth",
       "depthTest": true,
       "depthWrite": true,
       "dithering": false,
       "flatShading": false,
       "fog": true,
       "lights": false,
       "map": null,
       "morphTargets": false,
       "name": "",
       "opacity": 1,
       "overdraw": 0,
       "polygonOffset": false,
       "polygonOffsetFactor": 0,
       "polygonOffsetUnits": 0,
       "precision": null,
       "premultipliedAlpha": false,
       "shadowSide": null,
       "side": "FrontSide",
       "size": 0.1,
       "sizeAttenuation": true,
       "transparent": false,
       "type": "PointsMaterial",
       "vertexColors": "VertexColors",
       "visible": true
      }
     },
     "78db84fa486848f686977f93545f809a": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "WebGLShadowMapModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "WebGLShadowMapModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "enabled": false,
       "type": "PCFShadowMap"
      }
     },
     "87d610547c8d46b8a337cbed38da3e50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": "",
       "handle_color": null
      }
     },
     "91a6ea051c394649990df56ec3b14428": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "PointsModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "PointsModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "castShadow": false,
       "children": [],
       "frustumCulled": true,
       "geometry": "IPY_MODEL_b27e5ce9b88b4a51b10803fcb42e70ed",
       "material": "IPY_MODEL_593f1acdace644399853d7760aeaa4d7",
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "position": [
        0,
        0,
        0
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "Points",
       "up": [
        0,
        1,
        0
       ],
       "visible": true
      }
     },
     "b19df09190854180a49f40a7e33c7e42": {
      "buffers": [
       {
        "data": "sW+ePsLzpj4yvx4/ghTwPijfaj+3/SY/p1EkP7hoDT+Aa00/hhMyPxdTUz8xISM/0IR6P/fDjj54OXo/wUNVP0utRT+odxM+JuhoP2XSLD/0tnE+4+NFPw49bT+2ICI+yujiPuRV6z5dzIY+FgxLPxOnSz9UyuQ+QZfMPaJuJj9E1iQ/q7TBPSLinz7C2nA/bbDxPk8RnD5hSqg+xVFCP/uBHD9r+1g+IjqMPjzINj8ao2M/b0d+PqeTPT+eYqc+6gtlPxbD/T6vnh8+uJLSPpKnGT/prR0/O945PrHFSj+srw0+u+4VP8i1lD4XTzg/rXZDP0I7Zz9aqjc/uqpTP5DO0z5ifm8/u4OKPg/EYj9IJ4o+ar4MP5+FTT/QunA/G0/TPctM6z7v5bw91eoDPz/tLj8VHkE/47+sPlw4Kz4n32A/tIZJPYiX/D5h5Vw918tdP3yYVz/GMAc/6fM1PwLmaT8rvZw+TnFQP10M1z4mgwg/2ahnPR4Puj4SE3k/Yts6PyWlQT6wZSQ/hKF+PiVbNj9DuuA+keZmP0/5VD89NlI+bvb/Pqp1wzk51H4/LBNhP2dCRz24xWk+DnPhPaxYSz+IxWw/7vkoPz03XT4TJrY+vN0BPtl+Rz4JhJY+39HhPboq0T0mNQA+NZR+PyIRHD937kg+uCXDPRBiLz5M6BE/A1hlPvRqOT9xCCY/zSmKPvUYRT9ySoE+4FEgP8MupT4PNRY/7XddP23L5T4TyAE/QpatPSKYfD77mxo/4/T0PvEv/z4wrFM+KtEFP8/k0D6glfc+dtuaPu6DVD5Cbs07R1wiP/rXPT/EihA96bRzPxEcdD80YJo+K0FOP2Mtnz6ekPw+QTIaPnGeJT/oxxM/6O0FPzPsmT3Uslg/CfBeP/I8Vz+DsPY+CI0ePZAqbD06j28/yjbePgXW7z7pTVw9cDEpPwE2tD6o6Uo/NYX5PsiQ4T63HEE8VrNkP4ybRz7qBs8+xe4yP1gQez/A3RY9WYU4P8Re+T5DP5w+1Q1wP2jFBT/raSE/MWPBPe5UAj/OLDU/tPWoPtIZMz/ECPg+7UE/PiYucz/jsWA/3eJ9PsqtXj8Ya1k+BKqTPsBUqj5HMCM/gSixPma7cj6joRM/ixulPjOJxzxCUkQ/3YtePo22aj6h6XU/NhgxPtaQND9lBnc/7b16P2RYtDxcOSU/j93mPhvMOD6YRcw+311bPy+7lT4U00E/qY0nP4NRIT6mKRA+HHkHP7unND+Izlo/qYc2PxeKTD98YF4/A9mCPi5uGj5RHvg+TAInPlReaD87NEE7dM3WPnMMCD9vIm0/9IOzPrWZKD6KWCg/iNdhP6ooZT8nBfM9lnGdPrTofj+XmGw/EUpkP0FctD7C91Y/buliP/lkbD8Ie14/6Kh8P2b+wjv2cj0/PreZPp8Lfj/h8H8+v8/HPimZ2D5ZMIg+puh8PzWNTz9EQ08/j8rwPvu2tz5dJE4/5XuKPUZk+D5dJuE+VII3P/atQD4xB3o/ZDh0Py0umj5VgH8/qt7YPvfc7z7hVmA//yOpPtA68T426Vk/P53lPvtP4T7oCT8/uV7CPlmqHj5yqBI/",
        "encoding": "base64",
        "path": [
         "array",
         "buffer"
        ]
       }
      ],
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "BufferAttributeModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "BufferAttributeModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "array": {
        "dtype": "float32",
        "shape": [
         100,
         3
        ]
       },
       "dynamic": false,
       "needsUpdate": false,
       "normalized": true,
       "version": -1
      }
     },
     "b27e5ce9b88b4a51b10803fcb42e70ed": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "BufferGeometryModel",
      "state": {
       "MaxIndex": 65535,
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "BufferGeometryModel",
       "_ref_geometry": null,
       "_store_ref": false,
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "attributes": {
        "color": "IPY_MODEL_b19df09190854180a49f40a7e33c7e42",
        "position": "IPY_MODEL_d448637c348540a48f4e9b9691bb1702"
       },
       "index": null,
       "morphAttributes": {},
       "name": "",
       "type": "BufferGeometry",
       "userData": {}
      }
     },
     "d448637c348540a48f4e9b9691bb1702": {
      "buffers": [
       {
        "data": "wmBeP4lBhD8jCwE+xjM5v6UuUb7Z7p4+wu+Wvyi1w797zzo/7o3Uv511mj5TdCS/jNQMQMe3wb8nXqG/Jop4P0rjnr+FEue8zhZHv0YrZL9w9ye/i4PeP05Nxr5hxQO/qCMXP7JymT8DLh7AVoaLv3HQe7810sO+CZQFP32ZXL87jMC7ngrSv08nJjnvngy8OOCXPzLonT5+wCY/wc/FPXG1MT1XiLM/N1coPwLebD+U/aa/SlNZv+AH7r+GSIq/IKd+v/A1az8RVKq/Vddjvyg5sj/DSOI8neJpPUJ3pz9pvTI/eQeyPhYuhL0t1za/G3JlvgEKsT7UfhE/wWOHv2D/8z1Bn+O/4FycvoyQhriPJHe+t3YEwBzBST8Am6+7WPahv+TmQz4sUZc/YL0XvyJeW77sNQG/SnzQPqTQlz98noA/vV5hvz6zDj9j8es9dEkAwHR6/z+qkgfAamvPPnpaKL+ClkY/AEI8P2V3ir+IPem/5Y9Iv6xjwD4P/sa+fh6fP0H3Iz/9mSu/7woSv/VaCj+WmY8/zusaP+rXa75GCoi/b3SPvo+LJb/y6Ou+p73qPyjlNb+E5oU+x+gBP6YH9742YJa/kOB4vos+or+3jGq8kYi1v+R/fD+JxKO9Oz+nP3CXB0CfteO/XjsivzrLbLtlHLI/yP+Tv3aBCMDHD+c+2t4BPEiRhT9em4k9AVTmvjtRgb89hYC/Nmsyv2x3zj9IuN6+MzNrP4NLCT+zLkq/UydCP8E1XD/m6cG/pRJXv1ajzz6pJLu/RuNWPkLzOD4ABby+U8zYvm3uyr6FeBs/PvDZvRf6jL/03+y/2gYyv2SBbr7A0xvAK1dbvzihQj6O5sk/wwr7vzJyoL8GIOg+0uBVvq2FoT6KdR1Al3sowD/Ok7+zhkc/fflKv6RZlT6PGm0/SV5Ovu+IGr+1Rgy/dMEgwDmDZL+8pg8/sPAsvjlvgj3o0cy/8xZrvCgMk795PEU/fcu2P2Wc4L5AhZM/Fvlov0evyj9doLm+fxVOvxw92D5GjGA9vgeJP+Vydr8d37Q/qnFXP5ke4Tzmtji8CxgzPzVY97/Qtlk/h0ImvwsEgb+YlWk/QhX9vE++f78eDZW/5VaPPmTtYb93uhE+xvLXvrz7i74xX28/c+WVvi619j4mAAy+51gSP+p7m7/JUQy/ZS3xP+uz3D/0dTu/KZGCviHb8L9D8vS/saDCv6aB6D6Dfbm/WrIuv1gesb7Zd5k/xOY6P0g4XD3b8Yq/Y9tkP+YHlb9DEEg/utGbvv0SwT+SZbe/syZPPzTfX7/AvH+/EpjQv30X3T+qa4G/VRCbvwOwzbwXOoM/akqAvrUR6b7ntIM9Ym9uv18zub5rS24/ETXyPxdwE79Vl1A/hEiTP4jpNr67ce4+xWCZP3zwy7/EdA6/g6C9vndwEr/IAJQ/e8uEvq1gKz5TL7m+QmIVP/612L/HDDE+3d9CPmEee74TO949m0ihv0Ds+7+Ay1K/JDegPm9FOL9Roy0/+30LvLj8ED9/uEy+MFdhvjWzqz6v2KW/uV56P3+Lpz/Sdoe/JTF3vj9F47/zGCc+Dhc8Pjyo4j4jAAK/",
        "encoding": "base64",
        "path": [
         "array",
         "buffer"
        ]
       }
      ],
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "BufferAttributeModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "BufferAttributeModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "array": {
        "dtype": "float32",
        "shape": [
         100,
         3
        ]
       },
       "dynamic": false,
       "needsUpdate": false,
       "normalized": true,
       "version": -1
      }
     },
     "ed663176de34431db45f0ed95d182d5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efffc72c814b445bb3a9eac395e4bf2f": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "PerspectiveCameraModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "PerspectiveCameraModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "aspect": 1.5,
       "castShadow": false,
       "children": [],
       "far": 2000,
       "focus": 10,
       "fov": 50,
       "frustumCulled": true,
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldInverse": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "near": 0.1,
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "position": [
        5,
        5,
        5
       ],
       "projectionMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "PerspectiveCamera",
       "up": [
        0,
        1,
        0
       ],
       "visible": true,
       "zoom": 1
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
