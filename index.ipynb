{
 "cells": [
  {
   "cell_type": "raw",
   "id": "170215c2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"{{< var pub.title >}} --\"\n",
    "date: 'January 1, 2025'\n",
    "abstract-title: \"Summary\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2ab58-9efe-4758-a50d-8f9e011fe2cd",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Despite the header being `## Abstract`, this section will render as a highlighted section titled *Summary*. Ensure this section is a **maximum** of 280 characters.\n",
    "\n",
    "----\n",
    "\n",
    ":::{.callout-note title=\"AI usage disclosure\" collapse=\"true\"}\n",
    "This is a placeholder for the AI usage disclosure. Once all authors sign the AI code form on Airtable, SlackBot will message you an AI disclosure that you should place here.\n",
    ":::\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Once edited by you, this file will become your publication. Alternatively, if you already have a notebook written that you're trying to transform into a pub, replace this file with your own, but be sure to add the YAML front matter (the first cell) to your notebook.\n",
    "\n",
    "Your pub should begin with a section titled **Purpose** where you, as briefly as possible, explain why you did the work described in the pub, the key takeaway, your primary audience, and how you think it could be useful to them/why you're sharing it.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The MSA Pairformer achieves state-of-the-art performance in protein structure and function prediction, in large part due to its innovative query-biased attention mechanism [@Akiyama2025]. The authors put forward a compelling hypothesis for this success: by learning to weight sequences based on their evolutionary relevance to a query, the model mitigates phylogenetic averaging and amplifies faint, subfamily-specific signals.\n",
    "\n",
    "This interpretation is both powerful and likely correct. The model's impressive performance, especially in challenging cases with diverse subfamilies, strongly suggests it captures more than just superficial sequence identity. The natural next step, therefore, is to move from hypothesis to characterization. How precisely does the model's attention mechanism map onto the underlying phylogenetic structure of an MSA? In what regimes does it excel at recapitulating evolutionary history, and where are its limits?\n",
    "\n",
    "In this work, we explore these questions directly. We begin by performing a deep anatomical study of the paper's original case study—the response regulator family—and then expand our analysis to thousands of MSAs across the tree of life. Our goal is not simply to validate the authors' claim, but to scope out the space—to quantify the relationship between learned weights and genuine tree-based distances, providing a clearer picture of the model's remarkable capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e6bb5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Revisiting the response regulator study\n",
    "\n",
    "The response regulator (RR) family was the original paper's showcase for demonstrating the power of query-biased attention. By constructing a mixed MSA of GerE, LytTR, and OmpR subfamilies, the authors showed their model could successfully identify key structural contacts unique to each lineage, a task where standard methods failed.\n",
    "\n",
    "They illustrated the mechanism behind this success by plotting learned sequence weights against Hamming distance, revealing that members of the query's subfamily were consistently upweighted.\n",
    "\n",
    "![Figure 4B from @Akiyama2025. Original caption: \"*Median sequence weight across the layers of the model versus Hamming distance to the query sequence. Top panels show distribution of sequence attention weights for subfamily members (red) and non-subfamily sequences (grey). Grey dotted line indicates weights used for uniform sequence attention and red dotted line indicates weight assigned to the query sequence.*\"](assets/figure4b.jpg){fig-align=\"center\" width=100% fig-alt=\"Figure 4B from @Akiyama2025 showing the relationship between median sequence weight and Hamming distance to the query.\"}\n",
    "\n",
    "This provides strong evidence for the model's ability to group similar sequences. To build on this finding, we can refine the analysis by replacing the proxy of Hamming distance with a formal phylogenetic tree. This allows us to ask a more nuanced question: Do the learned weights reflect the continuous distances and specific branching patterns of evolutionary history, or do they simply create a binary distinction between \"in-group\" and \"out-group\"?\n",
    "\n",
    "To ground our phylogenetic analysis in the paper's original findings, we must first replicate their specific MSA. We begin by downloading the full PFAM alignments for the GerE, LytTR, and OmpR subfamilies, combining them, and then sampling a final set of 4096 sequences to match the dataset used in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4a911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:31.815112Z",
     "iopub.status.busy": "2025-10-06T19:53:31.814650Z",
     "iopub.status.idle": "2025-10-06T19:53:31.848506Z",
     "shell.execute_reply": "2025-10-06T19:53:31.847952Z"
    }
   },
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "%env USE_MODAL=1\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e4a07",
   "metadata": {},
   "source": [
    ":::{.callout-note title=\"Reproducing the response regulator MSAs\"}\n",
    "\n",
    "@Akiyama2025 qualitatively describe how to reproduce the response regulator MSAs, however these details are insufficient for exact replication. The code below is our attempted reproduction, and we find these MSAs yield similar, yet not identical, sequence weight statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9109183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:31.850808Z",
     "iopub.status.busy": "2025-10-06T19:53:31.850627Z",
     "iopub.status.idle": "2025-10-06T19:53:34.160754Z",
     "shell.execute_reply": "2025-10-06T19:53:34.160353Z"
    }
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Response regulator MSA code\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from analysis.pfam import download_and_process_response_regulator_msa\n",
    "\n",
    "from MSA_Pairformer.dataset import MSA\n",
    "\n",
    "response_regulator_dir = Path(\"./data/response_regulators\")\n",
    "response_regulator_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rr_msas: dict[str, MSA] = {}\n",
    "\n",
    "rr_queries = {\"1NXS\": \"OmpR\", \"4CBV\": \"LytTR\", \"4E7P\": \"GerE\"}\n",
    "for query in rr_queries:\n",
    "    msa_path = response_regulator_dir / f\"PF00072.final_{query}.a3m\"\n",
    "\n",
    "    if not msa_path.exists():\n",
    "        download_and_process_response_regulator_msa(\n",
    "            output_dir=response_regulator_dir,\n",
    "            subset_size=4096,\n",
    "        )\n",
    "\n",
    "    rr_msas[query] = MSA(msa_file_path=msa_path, diverse_select_method=\"none\")\n",
    "\n",
    "example_msa = rr_msas[query]\n",
    "membership_path = response_regulator_dir / \"membership.txt\"\n",
    "target_to_subfamily = (\n",
    "    pd.read_csv(membership_path, sep=\"\\t\").set_index(\"record_id\")[\"subfamily\"].to_dict()\n",
    ")\n",
    "\n",
    "print(f\"MSA has {len(example_msa.ids_l)} sequences:\")\n",
    "\n",
    "subfamily_member_count = Counter()\n",
    "for sequence in example_msa.ids_l:\n",
    "    subfamily_member_count[target_to_subfamily[sequence]] += 1\n",
    "\n",
    "for subfamily, count in subfamily_member_count.items():\n",
    "    print(f\"  - {subfamily} sequences: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e7123",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "With the response regulator MSA reconstructed, we can now move beyond simple sequence comparisons and infer the phylogenetic relationships among its members. We use FastTree, a rapid method for approximating maximum-likelihood phylogenies suitable for trees of this size, to build a tree from our alignment [@Price2009]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099474ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Tree inference code\n",
    "\n",
    "from analysis.tree import read_newick, run_fasttree\n",
    "\n",
    "fasttree_path = response_regulator_dir / \"PF00072.final.fasttree.newick\"\n",
    "msa_for_tree = response_regulator_dir / \"PF00072.final.fasta\"\n",
    "if not fasttree_path.exists():\n",
    "    run_fasttree(msa_path.with_suffix(\".fasta\"), fasttree_path)\n",
    "\n",
    "rr_tree = read_newick(fasttree_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f46270",
   "metadata": {},
   "source": [
    "Visualizing this tree provides our first direct look at the evolutionary structure of the data. We expect to see distinct, well-supported clades corresponding to the three subfamilies. This visual confirmation is a critical first step before we begin to quantify the relationship between the tree's structure and the model's learned attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | label: fig-rr-tree\n",
    "# | fig-cap: A randomly selected subset of the response regulator family illustrating the tree structure. The tree was calculated with FastTree. The RSCB structure ID is labelled for the query sequence of each subfamily. Leaves are colored according to subfamily  ([⬤]{style=\"color:#5088C5\"} [GerE](https://www.ebi.ac.uk/interpro/entry/pfam/PF00196/), [⬤]{style=\"color:#F28360\"} [OmpR](https://www.ebi.ac.uk/interpro/entry/pfam/PF00486/), [⬤]{style=\"color:#3B9886\"} [LytTR](https://www.ebi.ac.uk/interpro/entry/pfam/PF04397/)).\n",
    "\n",
    "import arcadia_pycolor as apc\n",
    "from analysis.plotting import tree_style_with_categorical_annotation\n",
    "from analysis.tree import read_newick, subset_tree\n",
    "\n",
    "query_colors = {\n",
    "    \"4E7P\": apc.aegean,\n",
    "    \"1NXS\": apc.amber,\n",
    "    \"4CBV\": apc.seaweed,\n",
    "}\n",
    "subfamily_colors = {rr_queries[k]: v for k, v in query_colors.items()}\n",
    "\n",
    "tree_style = tree_style_with_categorical_annotation(\n",
    "    categories=target_to_subfamily,\n",
    "    highlight=list(rr_queries),\n",
    "    color_map=subfamily_colors,\n",
    ")\n",
    "visualized_tree = subset_tree(tree=rr_tree, n=100, force_include=list(rr_queries), seed=42)\n",
    "visualized_tree.render(\"%%inline\", tree_style=tree_style, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13247c9",
   "metadata": {},
   "source": [
    "Our phylogenetic tree provides the evolutionary \"ground truth.\" Now, we need to generate the model's data to compare against it. We are specifically interested in the sequence attention weights, which, according to the paper's central hypothesis, are the mechanism by which the model captures this evolutionary information.\n",
    "\n",
    "To probe the model's query-biased behavior, let's run an MSA Pairformer inference on our MSA three separate times. In each run, let's set the representative from each subfamily (GerE, LytTR, and OmpR) as the query. This process will yield three distinct sets of attention weights, each representing the model's perspective from a different starting point in the evolutionary landscape.\n",
    "\n",
    ":::{.callout-note title=\"Running MSA Pairformer...\"}\n",
    "In order to reproduce this step of the workflow, you'll need a GPU with at least 40Gb of GPU VRAM. Since we don't assume the hardware that may be available for you, we've stored pre-computed inference results (`data/response_regulators/inference_results.pt`), and by default, the code below will load these inference results rather then attempting to re-compute this expensive operation. If you have the available hardware and want to re-compute the inference, delete this file and the cell below will regenerate them using your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c577a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:35.897200Z",
     "iopub.status.busy": "2025-10-06T19:53:35.897097Z",
     "iopub.status.idle": "2025-10-06T19:53:36.398419Z",
     "shell.execute_reply": "2025-10-06T19:53:36.398052Z"
    }
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: MSA inference code\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from analysis.pairformer import run_inference\n",
    "\n",
    "inference_results_path = response_regulator_dir / \"inference_results.pt\"\n",
    "if inference_results_path.exists():\n",
    "    rr_inference_results = torch.load(inference_results_path, weights_only=True)\n",
    "else:\n",
    "    rr_inference_results: dict[str, dict[str, Any]] = {}\n",
    "    for query in rr_queries:\n",
    "        rr_inference_results[query] = run_inference(\n",
    "            rr_msas[query], return_seq_weights=True, query_only=True\n",
    "        )\n",
    "\n",
    "    torch.save(rr_inference_results, inference_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4239703",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "We now have our two key components: a **phylogenetic tree** for the RR family (our evolutionary \"ground truth\") and the model's **attention weights** relative to each of the three subfamily queries. Before diving into a formal statistical analysis, let's build an intuition for how the model's attention relates to tree structure by visualizing weights directly onto the tree.\n",
    "\n",
    "For each of the three queries, let's center our view on a small subset of the full MSA (for ease of visualization) and color at each leaf the median attention weight it received from the model. If the model is indeed capturing evolutionary relevance, we should expect a gradient of attention that follows the tree's branches away from the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c85d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | label: fig-tree-weight-paint\n",
    "# | fig-cap: Trees for each query, where each leaf is colored according to the median sequence weight it received from the model. Darker nodes signify sequences receiving high levels of attention (upweighting), while lighter nodes signify sequence receiving low levels of attention (downweighting). Each tree is subset to 100 sequences sampled from the full tree (includes all subfamilies). To better visualize a gradient, sequences were sampled with a probability inversely proportional to their phylogenetic rank distance from the query, raised to a power of 0.8, which overall gives slight preference for selecting sequences phylogenetically similar to the query.\n",
    "# | fig-subcap:\n",
    "# |   - \"Median attention weights with respect to 1NXS (OmpR).\"\n",
    "# |   - \"Median attention weights with respect to 4CBV (LytTR).\"\n",
    "# |   - \"Median attention weights with respect to 4E7P (GerE).\"\n",
    "# | layout-ncol: 1\n",
    "\n",
    "from analysis.data import get_sequence_weight_data\n",
    "from analysis.plotting import tree_style_with_scalar_annotation\n",
    "from analysis.tree import (\n",
    "    sort_tree_by_reference,\n",
    "    subset_tree_around_reference,\n",
    ")\n",
    "from IPython.display import display\n",
    "\n",
    "rr_data_dict = dict(\n",
    "    query=[],\n",
    "    target=[],\n",
    "    median_weight=[],\n",
    ")\n",
    "\n",
    "for query in rr_queries:\n",
    "    msa = rr_msas[query]\n",
    "    targets = msa.ids_l\n",
    "\n",
    "    weights = get_sequence_weight_data(rr_inference_results[query])\n",
    "\n",
    "    # For each layer, sequence weights sum to 1. Scaling by number of\n",
    "    # sequences yields a scale where 1 implies uniform weighting.\n",
    "    weights *= weights.size(0)\n",
    "\n",
    "    median_weights = torch.median(weights, dim=1).values\n",
    "\n",
    "    rr_data_dict[\"query\"].extend([query] * len(targets))\n",
    "    rr_data_dict[\"target\"].extend(targets)\n",
    "    rr_data_dict[\"median_weight\"].extend(median_weights.tolist())\n",
    "\n",
    "response_regulator_df = pd.DataFrame(rr_data_dict)\n",
    "\n",
    "tree_images = []\n",
    "queries_list = response_regulator_df[\"query\"].unique()\n",
    "for query in queries_list:\n",
    "    color = query_colors[query]\n",
    "    specific_layer = \"median_weight\"\n",
    "    specific_layer_weights = (\n",
    "        response_regulator_df.loc[\n",
    "            (response_regulator_df[\"query\"] == query) & (response_regulator_df[\"query\"] != response_regulator_df[\"target\"]), [specific_layer, \"target\"]\n",
    "        ]\n",
    "        .set_index(\"target\")[specific_layer]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    gradient = apc.Gradient.from_dict(\n",
    "        \"gradient\",\n",
    "        {\"1\": \"#EEEEEE\", \"2\": \"#EEEEEE\", \"3\": color, \"4\": color},\n",
    "        values=[0.0, 0.0, 0.75, 1.0],\n",
    "    )\n",
    "    tree_style = tree_style_with_scalar_annotation(\n",
    "        specific_layer_weights, gradient, highlight=[query]\n",
    "    )\n",
    "    visualized_tree = sort_tree_by_reference(\n",
    "        subset_tree_around_reference(tree=rr_tree, n=100, reference=query, bias_power=0.8, seed=42),\n",
    "        query,\n",
    "    )\n",
    "    tree_images.append(visualized_tree.render(\"%%inline\", tree_style=tree_style, dpi=300))\n",
    "\n",
    "display(*tree_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06c75d",
   "metadata": {},
   "source": [
    "Encouragingly, @fig-tree-weight-paint provides an intuitive picture: weights with respect *1NXS* and *4CBV* visually correlate with distance from the query, suggesting the model's attention mechanism prioritizes evolutionary relatedness. However, the picture is less clear for *4E7P*, which invites a more rigorous, quantitative test.\n",
    "\n",
    "To formalize this observation, let's extract the *patristic tree distance*[^1] between each of the three queries and every other sequence in the MSA, then compare this to the median sequence weight the model assigned to each sequence. As in @Akiyama2025, we'll normalize weights by the number of sequences, so a value of 1 represents the uniform weighting baseline and a value greater than 1 indicates upweighting. And on the suspicion that this median value might smooth over layer-specific complexity, let's also store the individual weights from each layer to leave room for a more granular, layer-by-layer analysis.\n",
    "\n",
    "[^1]: Patristic tree distance is the distance between two members of a phylogenetic tree, calculated as the sum of branch lengths connecting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38773b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T19:53:36.400073Z",
     "iopub.status.busy": "2025-10-06T19:53:36.399872Z",
     "iopub.status.idle": "2025-10-06T19:53:36.779992Z",
     "shell.execute_reply": "2025-10-06T19:53:36.779469Z"
    }
   },
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "\n",
    "from analysis.data import get_sequence_weight_data\n",
    "from analysis.tree import get_patristic_distance\n",
    "from scipy.stats import linregress\n",
    "\n",
    "rr_data_dict = dict(\n",
    "    query=[],\n",
    "    target_subfamily=[],\n",
    "    target=[],\n",
    "    patristic_distance=[],\n",
    "    median_weight=[],\n",
    ")\n",
    "\n",
    "num_layers = 22\n",
    "for layer_idx in range(num_layers):\n",
    "    rr_data_dict[f\"layer_{layer_idx}_weight\"] = []\n",
    "\n",
    "for query in rr_queries:\n",
    "    msa = rr_msas[query]\n",
    "    targets = msa.ids_l\n",
    "\n",
    "    patristic_distances = get_patristic_distance(rr_tree, query)\n",
    "    patristic_distances = patristic_distances[targets]\n",
    "\n",
    "    weights = get_sequence_weight_data(rr_inference_results[query])\n",
    "\n",
    "    # For each layer, sequence weights sum to 1. Scaling by number of\n",
    "    # sequences yields a scale where 1 implies uniform weighting.\n",
    "    weights *= weights.size(0)\n",
    "\n",
    "    median_weights = torch.median(weights, dim=1).values\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        rr_data_dict[f\"layer_{layer_idx}_weight\"].extend(weights[:, layer_idx].tolist())\n",
    "\n",
    "    rr_data_dict[\"query\"].extend([query] * len(targets))\n",
    "    rr_data_dict[\"target_subfamily\"].extend(\n",
    "        [target_to_subfamily.get(target, \"Unknown\") for target in targets]\n",
    "    )\n",
    "    rr_data_dict[\"target\"].extend(targets)\n",
    "    rr_data_dict[\"median_weight\"].extend(median_weights.tolist())\n",
    "    rr_data_dict[\"patristic_distance\"].extend(patristic_distances.tolist())\n",
    "\n",
    "response_regulator_df = pd.DataFrame(rr_data_dict)\n",
    "response_regulator_df = response_regulator_df.query(\"query != target\").reset_index(drop=True)\n",
    "response_regulator_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b1528f",
   "metadata": {},
   "source": [
    "We can analyze the relationship between sequence weights and patristic distance with a simple linear regression. We'll frame the problem to directly assess the explanatory power of the model's sequence weights: how well can they explain the true evolutionary distance to the query?\n",
    "\n",
    "For each query $q$ and each target sequence $i$ in the MSA, let's define our model as:\n",
    "\n",
    "$$\n",
    "d_{i} = \\beta_1^{(l)} w_{i}^{(l)} + \\beta_0^{(l)}\n",
    "$$ {#eq-scalar-regression}\n",
    "\n",
    "where:\n",
    "\n",
    "- $d_{i}$ is the patristic distance from the query $q$ to the target sequence $i$.\n",
    "- $w_{i}^{(l)}$ is the normalized sequence weight assigned to sequence $i$ by a specific layer $l$.\n",
    "- $\\beta_1^{(l)}$ and $\\beta_0^{(l)}$ are the slope and intercept for the regression at layer $l$.\n",
    "\n",
    "Let's perform this regression independently for each of the three queries. For each query, we'll calculate the fit using the median weight across all layers and also for each of the 22 layers individually.\n",
    "\n",
    "We'll use the coefficient of determination ($R^2$) as the key statistic to measure the proportion of the variance in patristic distance that is explainable from the sequence weights. The following code calculates these regression statistics and generates an interactive plot to explore the relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | label: fig-rr-interactive\n",
    "# | fig-cap: An interactive display illustrating sequene weight versus patristic distance for each MSA member to the query. Each subplot represents the sequence weights relative to a different query. The dropdown controls which layer the sequence weights are from. By default, the median sequence weights across all layers are visualized. Black lines indicate the lines of best fit.\n",
    "\n",
    "import arcadia_pycolor as apc\n",
    "from analysis.plotting import interactive_layer_weight_plot\n",
    "\n",
    "regression_data = dict(\n",
    "    query=[],\n",
    "    layer=[],\n",
    "    r_squared=[],\n",
    "    p_value=[],\n",
    "    slope=[],\n",
    "    intercept=[],\n",
    ")\n",
    "\n",
    "for query in queries_list:\n",
    "    query_data = response_regulator_df[response_regulator_df[\"query\"] == query]\n",
    "    y = query_data[\"patristic_distance\"].values\n",
    "    x = query_data[\"median_weight\"].values\n",
    "    result = linregress(x, y)\n",
    "    regression_data[\"query\"].append(query)\n",
    "    regression_data[\"layer\"].append(\"median\")\n",
    "    regression_data[\"r_squared\"].append(result.rvalue**2)\n",
    "    regression_data[\"p_value\"].append(result.pvalue)\n",
    "    regression_data[\"slope\"].append(result.slope)\n",
    "    regression_data[\"intercept\"].append(result.intercept)\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        weight_col = f\"layer_{layer_idx}_weight\"\n",
    "        x = query_data[weight_col].values\n",
    "        result = linregress(x, y)\n",
    "        regression_data[\"query\"].append(query)\n",
    "        regression_data[\"layer\"].append(layer_idx)\n",
    "        regression_data[\"r_squared\"].append(result.rvalue**2)\n",
    "        regression_data[\"p_value\"].append(result.pvalue)\n",
    "        regression_data[\"slope\"].append(result.slope)\n",
    "        regression_data[\"intercept\"].append(result.intercept)\n",
    "\n",
    "rr_regression_df = pd.DataFrame(regression_data)\n",
    "rr_regression_df\n",
    "\n",
    "apc.plotly.setup()\n",
    "interactive_layer_weight_plot(response_regulator_df, rr_regression_df, rr_queries, subfamily_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60489b37",
   "metadata": {},
   "source": [
    "First, when viewing the median sequence weights (the default view), we observe a strong negative correlation with patristic distance across all three subfamilies. This provides direct, quantitative support for the original paper's central claim: on average, the model effectively learns to upweight evolutionarily closer sequences and downweight more distant ones.\n",
    "\n",
    "However, the layer-by-layer analysis uncovers a more nuanced and specialized division of labor within the model. The strength, and even the direction, of this correlation varies dramatically with network depth:\n",
    "\n",
    "* Strong Phylogenetic Filters: Some layers, such as layer 11, act as powerful phylogenetic filters. They exhibit a strong negative correlation ($R^2 > 0.6$), sharply penalizing sequences as their evolutionary distance from the query increases.\n",
    "* Alternative or Inverted Signals: In stark contrast, other layers show weak or even positive correlations. Layer 12, for instance, behaves inconsistently. When GerE is the query, it slightly upweights more distant sequences, suggesting it has learned a feature representation that is either independent of or runs counter to simple phylogenetic distance.\n",
    "\n",
    "This indicates that while the model as a whole successfully captures evolutionary relevance, this complex task is not distributed uniformly. Instead, specific layers appear to specialize in learning the phylogenetic structure of the MSA, while others focus on capturing different kinds of sequence information.\n",
    "\n",
    "Overall, @fig-rr-interactive shows a clear negative correlation between patristic distance and median sequence weight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe6650",
   "metadata": {},
   "source": [
    "## A survey across the tree of life\n",
    "\n",
    "Our analysis shows that median sequence weights correlate moderately with phylogenetic distance. More intriguingly, this layer-by-layer view has given us a peek behind the curtain, revealing a complex division of labor in how the model's attention mechanism captures evolutionary relatedness through the query-biased outer product.\n",
    "\n",
    "To understand how broadly these patterns hold, and to further characterize MSA Pairformer's understanding of evolutionary relationships, we need to see the extent this behavior generalizes by expanding our analysis to thousands of diverse protein families.\n",
    "\n",
    "To do this, we turn to the OpenProteinSet [@Ahdritz2023], a massive public database of protein alignments. This resource, derived from UniClust30 and [hosted on AWS](https://registry.opendata.aws/openfold/), provides the scale we need to move beyond our single case study.\n",
    "\n",
    "Inferring phylogenetic trees for all ~270,000 UniClust30 MSAs in the collection would require roughly 10 times the amount of patience most people possess. Furthermore, some of these MSAs would be unsuitable for our analysis for one reason or another. So to whittle this down to a more digestable size, we'll create the following procedure.\n",
    "\n",
    ":::{.callout-note title=\"MSA pre-processing workflow\"}\n",
    "\n",
    "First, randomly select 20,000 MSAs from the UniClust30 collection. Then, for each of the 20,000 MSAs, apply the following procedure:\n",
    "\n",
    "- Diversity selection: Select a diverse subset of up to 1024 sequences from the MSA\n",
    "    - Do this with the [MSA Pairformer API](https://github.com/yoakiyama/MSA_Pairformer/blob/33083d027788ee4a4295b554e782559b87e58fe5/MSA_Pairformer/dataset.py#L251-L276), which implements the sampling procedure introduced in MSA Transformer [@Rao2021]\n",
    "- Filter undesirables: Apply several checks that if the MSA does not pass, is discarded:\n",
    "    - Too shallow (fewer than 200 sequences) for downstream modelling (more on that later).\n",
    "    - Too long (over 1024 residues), posing computational constraints.\n",
    "    - Contains duplicate sequence identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | output: false\n",
    "import random\n",
    "\n",
    "from analysis.open_protein_set import fetch_all_ids, fetch_msas\n",
    "from analysis.sequence import write_processed_msa\n",
    "from analysis.utils import progress\n",
    "\n",
    "uniclust30_dir = Path(\"data\") / \"uniclust30\"\n",
    "uniclust30_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "msa_ids_path = uniclust30_dir / \"ids\"\n",
    "msa_ids = fetch_all_ids(cache_file=msa_ids_path)\n",
    "\n",
    "random.seed(42)\n",
    "msa_ids_subset = random.sample(msa_ids, k=20000)\n",
    "\n",
    "uniclust30_raw_msa_dir = uniclust30_dir / \"raw_msas\"\n",
    "uniclust30_raw_msa_dir.mkdir(exist_ok=True)\n",
    "\n",
    "raw_msa_paths = fetch_msas(msa_ids_subset, db_dir=uniclust30_raw_msa_dir)\n",
    "\n",
    "max_seq_length = 1024\n",
    "min_sequences = 200\n",
    "\n",
    "uniclust30_msa_dir = uniclust30_dir / \"msas\"\n",
    "uniclust30_msa_dir.mkdir(exist_ok=True)\n",
    "\n",
    "skipped_file = uniclust30_dir / \"skipped_ids\"\n",
    "if skipped_file.exists():\n",
    "    skipped_set = set(skipped_file.read_text().strip().split(\"\\n\"))\n",
    "else:\n",
    "    skipped_set = set()\n",
    "\n",
    "for id, raw_msa_path in progress(raw_msa_paths.items(), desc=\"Processing MSAs\"):\n",
    "    msa_path = uniclust30_msa_dir / f\"{id}.a3m\"\n",
    "\n",
    "    if msa_path.exists():\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    if id in skipped_set:\n",
    "        continue\n",
    "\n",
    "    msa = MSA(\n",
    "        raw_msa_path,\n",
    "        max_seqs=1024,\n",
    "        max_length=max_seq_length + 1,\n",
    "        diverse_select_method=\"hhfilter\",\n",
    "        secondary_filter_method=\"greedy\",\n",
    "    )\n",
    "\n",
    "    # Skip MSAs containing duplicate deflines. This likely occurs when multi-domain proteins\n",
    "    # generate multiple alignment hits. Duplicate names would cause tree construction to fail.\n",
    "    deflines = [msa.ids_l[idx] for idx in msa.select_diverse_indices]\n",
    "    if len(set(deflines)) != len(deflines):\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # We simplify verbose deflines from format tr|A0A1V5V6X5|LONG_SUFFIX to just A0A1V5V6X5.\n",
    "    # In rare cases (~0.5% of MSAs), simplification creates duplicates when both a consensus\n",
    "    # sequence (tr|ID|ID_consensus) and its non-consensus counterpart (tr|ID|ID_SPECIES)\n",
    "    # are present in the alignment. Rather than handle this edge case, we skip these MSAs.\n",
    "    simplified_deflines = [defline.split(\"|\")[1] for defline in deflines]\n",
    "    if len(set(simplified_deflines)) != len(simplified_deflines):\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # Skip MSAs exceeding maximum sequence length due to memory constraints\n",
    "    if msa.select_diverse_msa.shape[1] > max_seq_length:\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # Skip MSAs with too few sequences to avoid overfitting when modeling\n",
    "    # patristic distance with all 22 sequence weights.\n",
    "    if msa.select_diverse_msa.shape[0] < min_sequences:\n",
    "        skipped_set.add(id)\n",
    "        continue\n",
    "\n",
    "    # Write processed MSA to A3M format\n",
    "    write_processed_msa(msa, msa_path, format=\"a3m\", simplify_ids=True)\n",
    "\n",
    "_ = skipped_file.write_text(\"\\n\".join(skipped_set) + \"\\n\")\n",
    "\n",
    "msas = {}\n",
    "for msa_path in progress(sorted(uniclust30_msa_dir.glob(\"*.a3m\")), desc=\"Loading MSAs\"):\n",
    "    msas[msa_path.stem] = MSA(msa_path, diverse_select_method=\"none\")\n",
    "\n",
    "print(f\"Final MSA count: {len(msas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad6b01",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "Just like we did for the response regulator case, let's calculate a tree and sequence weights for each MSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6bbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating phylogenies\n",
    "# | output: false\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "from analysis.tree import run_fasttree_async\n",
    "\n",
    "uniclust30_tree_dir = uniclust30_dir / \"trees\"\n",
    "uniclust30_tree_dir.mkdir(exist_ok=True)\n",
    "\n",
    "jobs = []\n",
    "semaphore = asyncio.Semaphore(os.cpu_count() - 1)\n",
    "for a3m_path in uniclust30_msa_dir.glob(\"*.a3m\"):\n",
    "    fasttree_path = uniclust30_tree_dir / f\"{a3m_path.stem}.fasttree.newick\"\n",
    "    log_path = uniclust30_tree_dir / f\"{a3m_path.stem}.fasttree.log\"\n",
    "    if fasttree_path.exists():\n",
    "        continue\n",
    "\n",
    "    jobs.append(run_fasttree_async(a3m_path, fasttree_path, log_path, semaphore))\n",
    "\n",
    "_ = await asyncio.gather(*jobs)\n",
    "\n",
    "\n",
    "trees = {}\n",
    "for tree_path in progress(\n",
    "    sorted(uniclust30_tree_dir.glob(\"*.fasttree.newick\")),\n",
    "    desc=\"Loading trees\",\n",
    "):\n",
    "    id = tree_path.name.split(\".\")[0]\n",
    "    trees[id] = read_newick(tree_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating sequence weights\n",
    "from analysis.pairformer import calculate_sequence_weights\n",
    "\n",
    "seq_weights_path = uniclust30_dir / \"seq_weights.pt\"\n",
    "\n",
    "# When running on Modal, calculate_sequence_weights serializes MSAs to send to remote GPU workers.\n",
    "# Serializing all 11k+ MSAs at once exceeds Modal's serialization limits, so we batch into groups\n",
    "# of 1000. This constraint is specific to Modal's RPC layer. This batching choice is unnecessary\n",
    "# yet harmless for local execution.\n",
    "seq_weights = {}\n",
    "batch_size = 1000\n",
    "\n",
    "_msa_items = list(msas.items())\n",
    "\n",
    "if seq_weights_path.exists():\n",
    "    seq_weights = torch.load(seq_weights_path, weights_only=True)\n",
    "else:\n",
    "    for batch_start in progress(\n",
    "        range(0, len(_msa_items), batch_size), desc=\"Calculating sequence weights\"\n",
    "    ):\n",
    "        _batch_msas = dict(_msa_items[batch_start : batch_start + batch_size])\n",
    "        _batch_weights = calculate_sequence_weights(_batch_msas)\n",
    "        seq_weights.update(_batch_weights)\n",
    "\n",
    "    torch.save(seq_weights, seq_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51754b",
   "metadata": {},
   "source": [
    ":::{.callout-note title=\"For those following at home\" collapse=\"true\"}\n",
    "After running the above computations, you'll have the primary data in the following directories:\n",
    "\n",
    "* MSAs: `data/uniclust30/msas`\n",
    "* trees: `data/uniclust30/trees`\n",
    "* sequence weights: `data/unitclust30/seq_weights.pt`\n",
    "\n",
    "These data could be a prime launch point for followup studies.\n",
    ":::\n",
    "\n",
    "### Explanatory model across all layers\n",
    "\n",
    "In our response regulator case study, we performed simple linear regressions for each layer separately. This was a powerful visualization tool, giving us a peek at the \"division of labor\" by showing how the explanatory power of each layer varies in isolation.\n",
    "\n",
    "Now, with 11,000 MSAs processed, we can graduate to a more comprehensive question. Instead of asking how well *a single layer* predicts evolutionary distance, we can now ask:\n",
    "\n",
    "**How well do all 22 layers, when used *jointly*, predict phylogenetic distance?**\n",
    "\n",
    "This moves us from a set of simple regressions to a single multiple linear regression (per MSA). We must be clear about our goal: this is for **explanation, not prediction**. We are not building a generalizable model for held-out data. We're using this regression as a diagnostic tool to create a single, holistic score that quantifies the *in-sample explanatory power* of the model's complete set of weights.\n",
    "\n",
    "To formalize this, we define a **weight vector** $\\mathbf{w}_i$ for each sequence $i$, which stacks the normalized weights from all $L$ layers. Our model then finds the single coefficient vector $\\boldsymbol{\\beta}$ that best maps these weights to the patristic distance $d_i$:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_i = \\begin{bmatrix} w_i^{(1)} \\\\ w_i^{(2)} \\\\ \\vdots \\\\ w_i^{(L)} \\end{bmatrix} \\quad \\text{and} \\quad d_i = \\boldsymbol{\\beta}^T \\mathbf{w}_i + \\beta_0\n",
    "$$\n",
    "\n",
    "Because we are using 22 predictors ($k=22$), and some of our MSAs have a low number of sequences ($N$), a standard $R^2$ value could be misleadingly high. We will therefore use the **Adjusted $R^2$ ($R^2_{adj}$)**. This metric penalizes the score for each added predictor, providing a more conservative and honest measure of explanatory power.\n",
    "\n",
    "This $R^2_{adj}$ score is a **comparative metric**. It's not an absolute measure of performance, but a tool that allows us to finally explore how the model's phylogenetic awareness correlates with MSA properties, like depth, or how much it varies *at* a given depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Summarizing the data into a main table\n",
    "# | output: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from analysis.regression import regress_and_analyze_features\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def process_msa(query: str, dist_to_query: np.ndarray, weights: torch.Tensor) -> dict[str, Any]:\n",
    "    data = {}\n",
    "\n",
    "    # Regress the sequence weights against patristic distance.\n",
    "    # Perform an ANOVA (type III) to establish explanatory importance\n",
    "    # of each layer's sequence weights.\n",
    "    model, anova_table = regress_and_analyze_features(weights, dist_to_query)\n",
    "\n",
    "    data[\"Query\"] = query\n",
    "    data[\"Size\"] = len(dist_to_query)\n",
    "    data[\"R2\"] = model.rsquared\n",
    "    data[\"Adjusted R2\"] = model.rsquared_adj\n",
    "    data.update(anova_table[\"percent_sum_sq\"].to_dict())\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "jobs = []\n",
    "for query in seq_weights.keys():\n",
    "    msa = msas[query]\n",
    "    tree = trees[query]\n",
    "    weights = seq_weights[query]\n",
    "\n",
    "    size = len(tree.get_leaf_names())\n",
    "    if size < 200:\n",
    "        continue\n",
    "\n",
    "    dist_to_query = get_patristic_distance(tree, query)[msa.ids_l].values\n",
    "    jobs.append(delayed(process_msa)(query, dist_to_query, weights))\n",
    "\n",
    "results_df = pd.DataFrame(Parallel(-1)(jobs))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.plotting import ridgeline_r2_plot\n",
    "\n",
    "ridgeline_r2_plot(results_df, gradient=apc.gradients.verde.reverse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fe87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.plotting import stacked_feature_importance_plot\n",
    "\n",
    "stacked_feature_importance_plot(results_df, gradient=apc.gradients.verde.reverse())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8ac0",
   "metadata": {},
   "source": [
    "(describe, describe, etc)\n",
    "\n",
    "* MSA depth (aka tree size) does not explain much of the variance in performance.\n",
    "    * This is likely due to MSA Pairformer training dataset representing a broad range MSA depths\n",
    "* Tree size is a zeroth order parameter to describe tree topology\n",
    "* For trees a given size, the topology can be complex\n",
    "* Papers like [@Janzen2024] quantify tree topology characterization using dozens of metric\n",
    "    * They come to important conclusion that tree statistics are not easily normalizable by tree size\n",
    "        * This justifies characterizing MSA Pairformer with a tree-size normalized analysis\n",
    "        * We'll downsample to 200.\n",
    "    * They propose 3 statistics for joint use: Colless, cherry count, and phylogenetic diversity\n",
    "    * These metrics are global tree measures, but how the query is situated within the topology is equally important\n",
    "        * We'll add another set of measures related the Patristic distance distribution moments relative to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.sequence import filter_msa_by_tree, write_fasta_like\n",
    "from analysis.tree import write_newick\n",
    "\n",
    "uniclust30_msa_depth_200_dir = uniclust30_dir / \"msas_depth_200\"\n",
    "uniclust30_msa_depth_200_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "uniclust30_trees_depth_200_dir = uniclust30_dir / \"trees_depth_200\"\n",
    "uniclust30_trees_depth_200_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "msas_depth_200 = {}\n",
    "trees_depth_200 = {}\n",
    "\n",
    "for query, msa in progress(msas.items()):\n",
    "    tree = trees[query]\n",
    "    if len(tree.get_leaf_names()) < 200:\n",
    "        continue\n",
    "\n",
    "    msa_depth_200_path = uniclust30_msa_depth_200_dir / f\"{query}.a3m\"\n",
    "    tree_depth_200_path = uniclust30_trees_depth_200_dir / f\"{query}.fasttree.newick\"\n",
    "\n",
    "    if not msa_depth_200_path.exists() or not tree_depth_200_path.exists():\n",
    "        tree_subset = subset_tree(tree, n=200, force_include=[query], seed=42)\n",
    "        write_fasta_like(*filter_msa_by_tree(msa, tree_subset), msa_depth_200_path)\n",
    "        write_newick(tree_subset, tree_depth_200_path)\n",
    "\n",
    "    msas_depth_200[query] = MSA(msa_depth_200_path, diverse_select_method=\"none\")\n",
    "    trees_depth_200[query] = read_newick(tree_depth_200_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Calculating sequence weights\n",
    "seq_weights_depth_200_path = uniclust30_dir / \"seq_weights_depth_200.pt\"\n",
    "\n",
    "# When running on Modal, calculate_sequence_weights serializes MSAs to send to remote GPU workers.\n",
    "# Serializing all 11k+ MSAs at once exceeds Modal's serialization limits, so we batch into groups\n",
    "# of 1000. This constraint is specific to Modal's RPC layer. This batching choice is unnecessary\n",
    "# yet harmless for local execution.\n",
    "seq_weights_depth_200 = {}\n",
    "batch_size = 1000\n",
    "\n",
    "_msa_items = list(msas_depth_200.items())\n",
    "\n",
    "if seq_weights_depth_200_path.exists():\n",
    "    seq_weights_depth_200 = torch.load(seq_weights_depth_200_path, weights_only=True)\n",
    "else:\n",
    "    for batch_start in progress(\n",
    "        range(0, len(_msa_items), batch_size), desc=\"Calculating sequence weights\"\n",
    "    ):\n",
    "        _batch_msas = dict(_msa_items[batch_start : batch_start + batch_size])\n",
    "        _batch_weights = calculate_sequence_weights(_batch_msas)\n",
    "        seq_weights_depth_200.update(_batch_weights)\n",
    "\n",
    "    torch.save(seq_weights_depth_200, seq_weights_depth_200_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-fold: true\n",
    "# | code-summary: Summarizing the data into a main table\n",
    "# | output: false\n",
    "\n",
    "import pandas as pd\n",
    "from analysis.regression import regress_and_analyze_features\n",
    "from analysis.tree import (\n",
    "    cherry_count_statistic,\n",
    "    colless_statistic,\n",
    "    phylogenetic_diversity_statistic,\n",
    ")\n",
    "from ete3 import Tree\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def process_msa(query: str, dist_to_query: np.ndarray, tree: Tree, weights: torch.Tensor) -> dict[str, Any]:\n",
    "    data = {}\n",
    "\n",
    "    num_seqs = len(dist_to_query)\n",
    "\n",
    "    # Regress the sequence weights against patristic distance.\n",
    "    # Perform an ANOVA (type III) to establish explanatory importance\n",
    "    # of each layer's sequence weights.\n",
    "    model, anova_table = regress_and_analyze_features(weights, dist_to_query)\n",
    "\n",
    "    data[\"Query\"] = query\n",
    "    data[\"R2\"] = model.rsquared\n",
    "    data[\"Adjusted R2\"] = model.rsquared_adj\n",
    "    data[\"Mean patristic\"] = dist_to_query.mean()\n",
    "    data[\"Closest quartile patristic\"] = np.sort(dist_to_query)[:int(num_seqs // 4)].mean()\n",
    "    data[\"Phylogenetic diversity\"] = phylogenetic_diversity_statistic(tree)\n",
    "    data[\"Colless\"] = colless_statistic(tree)\n",
    "    data[\"Cherry count\"] = cherry_count_statistic(tree)\n",
    "    data.update(anova_table[\"percent_sum_sq\"].to_dict())\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "jobs = []\n",
    "for query in seq_weights_depth_200.keys():\n",
    "    msa = msas_depth_200[query]\n",
    "    tree = trees_depth_200[query]\n",
    "    weights = seq_weights_depth_200[query]\n",
    "\n",
    "    dist_to_query = get_patristic_distance(tree, query)[msa.ids_l].values\n",
    "    jobs.append(delayed(process_msa)(query, dist_to_query, tree, weights))\n",
    "\n",
    "results_depth_200_df = pd.DataFrame(Parallel(-1)(jobs))\n",
    "results_depth_200_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_depth_200_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3507f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_depth_200_df.to_csv(\"results.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebc5e8",
   "metadata": {},
   "source": [
    "## Experimental stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64abcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from analysis.data import get_sequence_weight_data\n",
    "from analysis.plotting import tree_style_with_scalar_annotation\n",
    "from analysis.tree import (\n",
    "    get_patristic_distance,\n",
    "    sort_tree_by_reference,\n",
    "    subset_tree_around_reference,\n",
    ")\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def plot_tree_with_weights(id: str, n: int = 400):\n",
    "    tree = trees[id]\n",
    "    msa = msas[id]\n",
    "    weights_tensor = seq_weights[id]\n",
    "\n",
    "    targets = msa.ids_l\n",
    "    weights = weights_tensor * weights_tensor.size(0)\n",
    "    median_weights = torch.median(weights, dim=0).values\n",
    "\n",
    "    weight_dict = {\n",
    "        target: weight.item() for target, weight in zip(targets, median_weights, strict=False)\n",
    "    }\n",
    "\n",
    "    gradient = apc.Gradient.from_dict(\n",
    "        \"gradient\",\n",
    "        {\"1\": \"#EEEEEE\", \"2\": \"#EEEEEE\", \"3\": apc.seaweed, \"4\": apc.seaweed},\n",
    "        values=[0.0, 0.0, 0.75, 1.0],\n",
    "    )\n",
    "    tree_style = tree_style_with_scalar_annotation(weight_dict, gradient, highlight=[id])\n",
    "    visualized_tree = sort_tree_by_reference(\n",
    "        subset_tree_around_reference(tree=tree, n=n, reference=id, bias_power=0.8, seed=42),\n",
    "        id,\n",
    "    )\n",
    "\n",
    "    return visualized_tree.render(\"%%inline\", tree_style=tree_style, dpi=300)\n",
    "\n",
    "\n",
    "for query in list(seq_weights.keys())[:3]:\n",
    "    print(query)\n",
    "    plot_regression(query).show()\n",
    "    # plot_tree_with_weights(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e606b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A0A022Y0Q6\"\n",
    "plot_tree_with_weights(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A0A009GC83\"\n",
    "plot_tree_with_weights(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.tree import (\n",
    "    cherry_count_statistic,\n",
    "    colless_statistic,\n",
    "    phylogenetic_diversity_statistic,\n",
    ")\n",
    "\n",
    "for _, tree in progress(trees.items()):\n",
    "    phylogenetic_diversity_statistic(tree)\n",
    "    colless_statistic(tree)\n",
    "    cherry_count_statistic(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7919c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.regression import regress_sequence_weights_on_patristic_distance\n",
    "\n",
    "id = \"A0A009GC83\"\n",
    "\n",
    "msa = msas[id]\n",
    "tree = trees[id]\n",
    "weights_tensor = seq_weights[id]\n",
    "\n",
    "targets = msa.ids_l\n",
    "patristic_distances = get_patristic_distance(tree, id)\n",
    "patristic_distances = patristic_distances[targets]\n",
    "\n",
    "model, r2 = regress_sequence_weights_on_patristic_distance(weights_tensor.cpu(), patristic_distances.values)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47919adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tree.get_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80172f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4673ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression(\"A0A2I1VP33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54767ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_these = []\n",
    "for query in seq_weights.keys():\n",
    "    msa = msas[query]\n",
    "    tree = trees[query]\n",
    "    try:\n",
    "        dist = get_patristic_distance(tree, query)[msa.ids_l].values\n",
    "    except:\n",
    "        fix_these.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fix_these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4aaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "from analysis.tree import run_fasttree_async\n",
    "\n",
    "uniclust30_tree_dir = uniclust30_dir / \"trees\"\n",
    "uniclust30_tree_dir.mkdir(exist_ok=True)\n",
    "\n",
    "inputs_for_tree_fixing = [Path(f\"./data/uniclust30/msas/{query}.a3m\") for query in fix_these]\n",
    "\n",
    "jobs = []\n",
    "semaphore = asyncio.Semaphore(os.cpu_count() - 1)\n",
    "for a3m_path in inputs_for_tree_fixing:\n",
    "    fasttree_path = uniclust30_tree_dir / f\"{a3m_path.stem}.fasttree.newick\"\n",
    "    log_path = uniclust30_tree_dir / f\"{a3m_path.stem}.fasttree.log\"\n",
    "\n",
    "    if fasttree_path.exists():\n",
    "        fasttree_path.unlink()\n",
    "    if log_path.exists():\n",
    "        log_path.unlink()\n",
    "\n",
    "    jobs.append(run_fasttree_async(a3m_path, fasttree_path, log_path, semaphore))\n",
    "\n",
    "_ = await asyncio.gather(*jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tree in trees.items():\n",
    "    if len(tree.get_leaf_names()) == 1024:\n",
    "        print(name)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef84a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.plotting import tree_style_with_highlights\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "query = \"A0A015LDC8\"\n",
    "tree = trees[query]\n",
    "\n",
    "images = []\n",
    "for power in np.linspace(-3, 3, 10):\n",
    "    subset = sort_tree_by_reference(subset_tree_around_reference(tree, 100, query, bias_power=power), query)\n",
    "    distances = get_patristic_distance(subset, query).values\n",
    "    print(distances.mean())\n",
    "    plt.hist(distances, bins=20)\n",
    "    plt.show()\n",
    "    #images.append(subset.render(\"%%inline\", tree_style=tree_style_with_highlights([query])))\n",
    "#display(*images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab75cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kktree.get_leaf_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8cc6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = trees[query]\n",
    "subset_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39384fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "2025-phylogenetic-analysis-of-msa-pairformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1daa3cc0ab3c4b3796c6acefe7b557c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "IntSliderView",
       "behavior": "drag-tap",
       "continuous_update": true,
       "description": "",
       "description_allow_html": false,
       "disabled": false,
       "layout": "IPY_MODEL_ed663176de34431db45f0ed95d182d5c",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_87d610547c8d46b8a337cbed38da3e50",
       "tabbable": null,
       "tooltip": null,
       "value": 0
      }
     },
     "21bf29f5d21c4695b0b6c51aff6a1212": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39a59ea193e14707a8fad835b674c771": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "OrbitControlsModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "OrbitControlsModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "autoRotate": false,
       "autoRotateSpeed": 2,
       "controlling": "IPY_MODEL_efffc72c814b445bb3a9eac395e4bf2f",
       "dampingFactor": 0.25,
       "enableDamping": false,
       "enableKeys": true,
       "enablePan": true,
       "enableRotate": true,
       "enableZoom": true,
       "enabled": true,
       "keyPanSpeed": 7,
       "maxAzimuthAngle": "inf",
       "maxDistance": "inf",
       "maxPolarAngle": 3.141592653589793,
       "maxZoom": "inf",
       "minAzimuthAngle": "-inf",
       "minDistance": 0,
       "minPolarAngle": 0,
       "minZoom": 0,
       "panSpeed": 1,
       "rotateSpeed": 1,
       "screenSpacePanning": true,
       "target": [
        0,
        0,
        0
       ],
       "zoomSpeed": 1
      }
     },
     "39db96ed75d34ded998a770bf6293fcf": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "SceneModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "SceneModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "autoUpdate": true,
       "background": "#ffffff",
       "castShadow": false,
       "children": [
        "IPY_MODEL_91a6ea051c394649990df56ec3b14428",
        "IPY_MODEL_42a8ed88d63a4b25b0998b12e39d7959"
       ],
       "fog": null,
       "frustumCulled": true,
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "overrideMaterial": null,
       "position": [
        0,
        0,
        0
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "Scene",
       "up": [
        0,
        1,
        0
       ],
       "visible": true
      }
     },
     "3d6f1e15b70e45369a6d95ffcb38fdb8": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "RendererModel",
      "state": {
       "_alpha": false,
       "_antialias": false,
       "_dom_classes": [],
       "_height": 400,
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "RendererModel",
       "_pause_autorender": false,
       "_view_count": null,
       "_view_module": "jupyter-threejs",
       "_view_module_version": "^2.4.1",
       "_view_name": "RendererView",
       "_webgl_version": 2,
       "_width": 600,
       "autoClear": true,
       "autoClearColor": true,
       "autoClearDepth": true,
       "autoClearStencil": true,
       "background": "black",
       "background_opacity": 1,
       "camera": "IPY_MODEL_efffc72c814b445bb3a9eac395e4bf2f",
       "clearColor": "#000000",
       "clearOpacity": 1,
       "clippingPlanes": [],
       "controls": [
        "IPY_MODEL_39a59ea193e14707a8fad835b674c771"
       ],
       "gammaFactor": 2,
       "gammaInput": false,
       "gammaOutput": false,
       "layout": "IPY_MODEL_21bf29f5d21c4695b0b6c51aff6a1212",
       "localClippingEnabled": false,
       "maxMorphNormals": 4,
       "maxMorphTargets": 8,
       "physicallyCorrectLights": false,
       "scene": "IPY_MODEL_39db96ed75d34ded998a770bf6293fcf",
       "shadowMap": "IPY_MODEL_78db84fa486848f686977f93545f809a",
       "sortObject": true,
       "tabbable": null,
       "toneMapping": "LinearToneMapping",
       "toneMappingExposure": 1,
       "toneMappingWhitePoint": 1,
       "tooltip": null
      }
     },
     "42a8ed88d63a4b25b0998b12e39d7959": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "AmbientLightModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "AmbientLightModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "castShadow": false,
       "children": [],
       "color": "#ffffff",
       "frustumCulled": true,
       "intensity": 1,
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "position": [
        0,
        0,
        0
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "AmbientLight",
       "up": [
        0,
        1,
        0
       ],
       "visible": true
      }
     },
     "593f1acdace644399853d7760aeaa4d7": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "PointsMaterialModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "PointsMaterialModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "alphaTest": 0,
       "blendDst": "OneMinusSrcAlphaFactor",
       "blendDstAlpha": 0,
       "blendEquation": "AddEquation",
       "blendEquationAlpha": 0,
       "blendSrc": "SrcAlphaFactor",
       "blendSrcAlpha": 0,
       "blending": "NormalBlending",
       "clipIntersection": false,
       "clipShadows": false,
       "clippingPlanes": [],
       "color": "#ffffff",
       "colorWrite": true,
       "defines": null,
       "depthFunc": "LessEqualDepth",
       "depthTest": true,
       "depthWrite": true,
       "dithering": false,
       "flatShading": false,
       "fog": true,
       "lights": false,
       "map": null,
       "morphTargets": false,
       "name": "",
       "opacity": 1,
       "overdraw": 0,
       "polygonOffset": false,
       "polygonOffsetFactor": 0,
       "polygonOffsetUnits": 0,
       "precision": null,
       "premultipliedAlpha": false,
       "shadowSide": null,
       "side": "FrontSide",
       "size": 0.1,
       "sizeAttenuation": true,
       "transparent": false,
       "type": "PointsMaterial",
       "vertexColors": "VertexColors",
       "visible": true
      }
     },
     "78db84fa486848f686977f93545f809a": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "WebGLShadowMapModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "WebGLShadowMapModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "enabled": false,
       "type": "PCFShadowMap"
      }
     },
     "87d610547c8d46b8a337cbed38da3e50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "description_width": "",
       "handle_color": null
      }
     },
     "91a6ea051c394649990df56ec3b14428": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "PointsModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "PointsModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "castShadow": false,
       "children": [],
       "frustumCulled": true,
       "geometry": "IPY_MODEL_b27e5ce9b88b4a51b10803fcb42e70ed",
       "material": "IPY_MODEL_593f1acdace644399853d7760aeaa4d7",
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "position": [
        0,
        0,
        0
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "Points",
       "up": [
        0,
        1,
        0
       ],
       "visible": true
      }
     },
     "b19df09190854180a49f40a7e33c7e42": {
      "buffers": [
       {
        "data": "sW+ePsLzpj4yvx4/ghTwPijfaj+3/SY/p1EkP7hoDT+Aa00/hhMyPxdTUz8xISM/0IR6P/fDjj54OXo/wUNVP0utRT+odxM+JuhoP2XSLD/0tnE+4+NFPw49bT+2ICI+yujiPuRV6z5dzIY+FgxLPxOnSz9UyuQ+QZfMPaJuJj9E1iQ/q7TBPSLinz7C2nA/bbDxPk8RnD5hSqg+xVFCP/uBHD9r+1g+IjqMPjzINj8ao2M/b0d+PqeTPT+eYqc+6gtlPxbD/T6vnh8+uJLSPpKnGT/prR0/O945PrHFSj+srw0+u+4VP8i1lD4XTzg/rXZDP0I7Zz9aqjc/uqpTP5DO0z5ifm8/u4OKPg/EYj9IJ4o+ar4MP5+FTT/QunA/G0/TPctM6z7v5bw91eoDPz/tLj8VHkE/47+sPlw4Kz4n32A/tIZJPYiX/D5h5Vw918tdP3yYVz/GMAc/6fM1PwLmaT8rvZw+TnFQP10M1z4mgwg/2ahnPR4Puj4SE3k/Yts6PyWlQT6wZSQ/hKF+PiVbNj9DuuA+keZmP0/5VD89NlI+bvb/Pqp1wzk51H4/LBNhP2dCRz24xWk+DnPhPaxYSz+IxWw/7vkoPz03XT4TJrY+vN0BPtl+Rz4JhJY+39HhPboq0T0mNQA+NZR+PyIRHD937kg+uCXDPRBiLz5M6BE/A1hlPvRqOT9xCCY/zSmKPvUYRT9ySoE+4FEgP8MupT4PNRY/7XddP23L5T4TyAE/QpatPSKYfD77mxo/4/T0PvEv/z4wrFM+KtEFP8/k0D6glfc+dtuaPu6DVD5Cbs07R1wiP/rXPT/EihA96bRzPxEcdD80YJo+K0FOP2Mtnz6ekPw+QTIaPnGeJT/oxxM/6O0FPzPsmT3Uslg/CfBeP/I8Vz+DsPY+CI0ePZAqbD06j28/yjbePgXW7z7pTVw9cDEpPwE2tD6o6Uo/NYX5PsiQ4T63HEE8VrNkP4ybRz7qBs8+xe4yP1gQez/A3RY9WYU4P8Re+T5DP5w+1Q1wP2jFBT/raSE/MWPBPe5UAj/OLDU/tPWoPtIZMz/ECPg+7UE/PiYucz/jsWA/3eJ9PsqtXj8Ya1k+BKqTPsBUqj5HMCM/gSixPma7cj6joRM/ixulPjOJxzxCUkQ/3YtePo22aj6h6XU/NhgxPtaQND9lBnc/7b16P2RYtDxcOSU/j93mPhvMOD6YRcw+311bPy+7lT4U00E/qY0nP4NRIT6mKRA+HHkHP7unND+Izlo/qYc2PxeKTD98YF4/A9mCPi5uGj5RHvg+TAInPlReaD87NEE7dM3WPnMMCD9vIm0/9IOzPrWZKD6KWCg/iNdhP6ooZT8nBfM9lnGdPrTofj+XmGw/EUpkP0FctD7C91Y/buliP/lkbD8Ie14/6Kh8P2b+wjv2cj0/PreZPp8Lfj/h8H8+v8/HPimZ2D5ZMIg+puh8PzWNTz9EQ08/j8rwPvu2tz5dJE4/5XuKPUZk+D5dJuE+VII3P/atQD4xB3o/ZDh0Py0umj5VgH8/qt7YPvfc7z7hVmA//yOpPtA68T426Vk/P53lPvtP4T7oCT8/uV7CPlmqHj5yqBI/",
        "encoding": "base64",
        "path": [
         "array",
         "buffer"
        ]
       }
      ],
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "BufferAttributeModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "BufferAttributeModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "array": {
        "dtype": "float32",
        "shape": [
         100,
         3
        ]
       },
       "dynamic": false,
       "needsUpdate": false,
       "normalized": true,
       "version": -1
      }
     },
     "b27e5ce9b88b4a51b10803fcb42e70ed": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "BufferGeometryModel",
      "state": {
       "MaxIndex": 65535,
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "BufferGeometryModel",
       "_ref_geometry": null,
       "_store_ref": false,
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "attributes": {
        "color": "IPY_MODEL_b19df09190854180a49f40a7e33c7e42",
        "position": "IPY_MODEL_d448637c348540a48f4e9b9691bb1702"
       },
       "index": null,
       "morphAttributes": {},
       "name": "",
       "type": "BufferGeometry",
       "userData": {}
      }
     },
     "d448637c348540a48f4e9b9691bb1702": {
      "buffers": [
       {
        "data": "wmBeP4lBhD8jCwE+xjM5v6UuUb7Z7p4+wu+Wvyi1w797zzo/7o3Uv511mj5TdCS/jNQMQMe3wb8nXqG/Jop4P0rjnr+FEue8zhZHv0YrZL9w9ye/i4PeP05Nxr5hxQO/qCMXP7JymT8DLh7AVoaLv3HQe7810sO+CZQFP32ZXL87jMC7ngrSv08nJjnvngy8OOCXPzLonT5+wCY/wc/FPXG1MT1XiLM/N1coPwLebD+U/aa/SlNZv+AH7r+GSIq/IKd+v/A1az8RVKq/Vddjvyg5sj/DSOI8neJpPUJ3pz9pvTI/eQeyPhYuhL0t1za/G3JlvgEKsT7UfhE/wWOHv2D/8z1Bn+O/4FycvoyQhriPJHe+t3YEwBzBST8Am6+7WPahv+TmQz4sUZc/YL0XvyJeW77sNQG/SnzQPqTQlz98noA/vV5hvz6zDj9j8es9dEkAwHR6/z+qkgfAamvPPnpaKL+ClkY/AEI8P2V3ir+IPem/5Y9Iv6xjwD4P/sa+fh6fP0H3Iz/9mSu/7woSv/VaCj+WmY8/zusaP+rXa75GCoi/b3SPvo+LJb/y6Ou+p73qPyjlNb+E5oU+x+gBP6YH9742YJa/kOB4vos+or+3jGq8kYi1v+R/fD+JxKO9Oz+nP3CXB0CfteO/XjsivzrLbLtlHLI/yP+Tv3aBCMDHD+c+2t4BPEiRhT9em4k9AVTmvjtRgb89hYC/Nmsyv2x3zj9IuN6+MzNrP4NLCT+zLkq/UydCP8E1XD/m6cG/pRJXv1ajzz6pJLu/RuNWPkLzOD4ABby+U8zYvm3uyr6FeBs/PvDZvRf6jL/03+y/2gYyv2SBbr7A0xvAK1dbvzihQj6O5sk/wwr7vzJyoL8GIOg+0uBVvq2FoT6KdR1Al3sowD/Ok7+zhkc/fflKv6RZlT6PGm0/SV5Ovu+IGr+1Rgy/dMEgwDmDZL+8pg8/sPAsvjlvgj3o0cy/8xZrvCgMk795PEU/fcu2P2Wc4L5AhZM/Fvlov0evyj9doLm+fxVOvxw92D5GjGA9vgeJP+Vydr8d37Q/qnFXP5ke4Tzmtji8CxgzPzVY97/Qtlk/h0ImvwsEgb+YlWk/QhX9vE++f78eDZW/5VaPPmTtYb93uhE+xvLXvrz7i74xX28/c+WVvi619j4mAAy+51gSP+p7m7/JUQy/ZS3xP+uz3D/0dTu/KZGCviHb8L9D8vS/saDCv6aB6D6Dfbm/WrIuv1gesb7Zd5k/xOY6P0g4XD3b8Yq/Y9tkP+YHlb9DEEg/utGbvv0SwT+SZbe/syZPPzTfX7/AvH+/EpjQv30X3T+qa4G/VRCbvwOwzbwXOoM/akqAvrUR6b7ntIM9Ym9uv18zub5rS24/ETXyPxdwE79Vl1A/hEiTP4jpNr67ce4+xWCZP3zwy7/EdA6/g6C9vndwEr/IAJQ/e8uEvq1gKz5TL7m+QmIVP/612L/HDDE+3d9CPmEee74TO949m0ihv0Ds+7+Ay1K/JDegPm9FOL9Roy0/+30LvLj8ED9/uEy+MFdhvjWzqz6v2KW/uV56P3+Lpz/Sdoe/JTF3vj9F47/zGCc+Dhc8Pjyo4j4jAAK/",
        "encoding": "base64",
        "path": [
         "array",
         "buffer"
        ]
       }
      ],
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "BufferAttributeModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "BufferAttributeModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "array": {
        "dtype": "float32",
        "shape": [
         100,
         3
        ]
       },
       "dynamic": false,
       "needsUpdate": false,
       "normalized": true,
       "version": -1
      }
     },
     "ed663176de34431db45f0ed95d182d5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efffc72c814b445bb3a9eac395e4bf2f": {
      "model_module": "jupyter-threejs",
      "model_module_version": "^2.4.1",
      "model_name": "PerspectiveCameraModel",
      "state": {
       "_model_module": "jupyter-threejs",
       "_model_module_version": "^2.4.1",
       "_model_name": "PerspectiveCameraModel",
       "_view_count": null,
       "_view_module": null,
       "_view_module_version": "",
       "_view_name": null,
       "aspect": 1.5,
       "castShadow": false,
       "children": [],
       "far": 2000,
       "focus": 10,
       "fov": 50,
       "frustumCulled": true,
       "matrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixAutoUpdate": true,
       "matrixWorld": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldInverse": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "matrixWorldNeedsUpdate": false,
       "modelViewMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "name": "",
       "near": 0.1,
       "normalMatrix": [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1
       ],
       "position": [
        5,
        5,
        5
       ],
       "projectionMatrix": [
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        1
       ],
       "quaternion": [
        0,
        0,
        0,
        1
       ],
       "receiveShadow": false,
       "renderOrder": 0,
       "rotation": [
        0,
        0,
        0,
        "XYZ"
       ],
       "scale": [
        1,
        1,
        1
       ],
       "type": "PerspectiveCamera",
       "up": [
        0,
        1,
        0
       ],
       "visible": true,
       "zoom": 1
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
